[
  {
    "case_id": "case_1",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "29115",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?",
      "matching_respondents": [
        "29115"
      ]
    }
  },
  {
    "case_id": "case_2",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have MainBranch A and CompTotal of 67000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "73215",
    "metadata": {
      "inference_question": "Which respondent numbers have MainBranch A and CompTotal of 67000.0?",
      "matching_respondents": [
        "73215"
      ]
    }
  },
  {
    "case_id": "case_3",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have Employment A and LanguageHaveWorkedWith containing Python?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "143, 297",
    "metadata": {
      "inference_question": "Which respondent numbers have Employment A and LanguageHaveWorkedWith containing Python?",
      "matching_respondents": [
        "143",
        "297"
      ]
    }
  },
  {
    "case_id": "case_4",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have EdLevel E and LanguageHaveWorkedWith containing Python?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "127",
    "metadata": {
      "inference_question": "Which respondent numbers have EdLevel E and LanguageHaveWorkedWith containing Python?",
      "matching_respondents": [
        "127"
      ]
    }
  },
  {
    "case_id": "case_5",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have DevType containing Developer, full-stack and ToolsTechHaveWorkedWith containing Docker?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72659, 73103, 73211",
    "metadata": {
      "inference_question": "Which respondent numbers have DevType containing Developer, full-stack and ToolsTechHaveWorkedWith containing Docker?",
      "matching_respondents": [
        "72659",
        "73103",
        "73211"
      ]
    }
  },
  {
    "case_id": "case_6",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCode of 26 and LanguageHaveWorkedWith containing PowerShell?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "73142",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCode of 26 and LanguageHaveWorkedWith containing PowerShell?",
      "matching_respondents": [
        "73142"
      ]
    }
  },
  {
    "case_id": "case_7",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have Employment A and EdLevel E?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "303",
    "metadata": {
      "inference_question": "Which respondent numbers have Employment A and EdLevel E?",
      "matching_respondents": [
        "303"
      ]
    }
  },
  {
    "case_id": "case_8",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have OrgSize 5,000 to 9,999 employees and LanguageHaveWorkedWith containing MATLAB?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "None",
    "metadata": {
      "inference_question": "Which respondent numbers have OrgSize 5,000 to 9,999 employees and LanguageHaveWorkedWith containing MATLAB?",
      "matching_respondents": []
    }
  },
  {
    "case_id": "case_9",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCodePro of 5 and ToolsTechHaveWorkedWith containing Homebrew?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "319",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCodePro of 5 and ToolsTechHaveWorkedWith containing Homebrew?",
      "matching_respondents": [
        "319"
      ]
    }
  },
  {
    "case_id": "case_10",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have EdLevel F and CompTotal of 320000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "475",
    "metadata": {
      "inference_question": "Which respondent numbers have EdLevel F and CompTotal of 320000.0?",
      "matching_respondents": [
        "475"
      ]
    }
  },
  {
    "case_id": "case_11",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCode of 15 and ToolsTechHaveWorkedWith containing Ansible?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72584",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCode of 15 and ToolsTechHaveWorkedWith containing Ansible?",
      "matching_respondents": [
        "72584"
      ]
    }
  },
  {
    "case_id": "case_12",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCodePro of 5 and CompTotal of 98000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "133",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCodePro of 5 and CompTotal of 98000.0?",
      "matching_respondents": [
        "133"
      ]
    }
  },
  {
    "case_id": "case_13",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageHaveWorkedWith containing Bash/Shell and ToolsTechHaveWorkedWith containing Terraform?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72916",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageHaveWorkedWith containing Bash/Shell and ToolsTechHaveWorkedWith containing Terraform?",
      "matching_respondents": [
        "72916"
      ]
    }
  },
  {
    "case_id": "case_14",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have Employment A and ToolsTechHaveWorkedWith containing Homebrew?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "183",
    "metadata": {
      "inference_question": "Which respondent numbers have Employment A and ToolsTechHaveWorkedWith containing Homebrew?",
      "matching_respondents": [
        "183"
      ]
    }
  },
  {
    "case_id": "case_15",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have MainBranch A and Employment A?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "136, 348",
    "metadata": {
      "inference_question": "Which respondent numbers have MainBranch A and Employment A?",
      "matching_respondents": [
        "136",
        "348"
      ]
    }
  },
  {
    "case_id": "case_16",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageWantToWorkWith containing VBA and ToolsTechHaveWorkedWith npm?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "None",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageWantToWorkWith containing VBA and ToolsTechHaveWorkedWith npm?",
      "matching_respondents": []
    }
  },
  {
    "case_id": "case_17",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have Employment A and LanguageWantToWorkWith containing C?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72734",
    "metadata": {
      "inference_question": "Which respondent numbers have Employment A and LanguageWantToWorkWith containing C?",
      "matching_respondents": [
        "72734"
      ]
    }
  },
  {
    "case_id": "case_18",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have EdLevel F and Country France?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "513",
    "metadata": {
      "inference_question": "Which respondent numbers have EdLevel F and Country France?",
      "matching_respondents": [
        "513"
      ]
    }
  },
  {
    "case_id": "case_19",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageHaveWorkedWith containing Java and ToolsTechHaveWorkedWith containing npm?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "29145, 72728",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageHaveWorkedWith containing Java and ToolsTechHaveWorkedWith containing npm?",
      "matching_respondents": [
        "29145",
        "72728"
      ]
    }
  },
  {
    "case_id": "case_20",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have CompTotal of 1130.0 and LanguageHaveWorkedWith containing SQL?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "379",
    "metadata": {
      "inference_question": "Which respondent numbers have CompTotal of 1130.0 and LanguageHaveWorkedWith containing SQL?",
      "matching_respondents": [
        "379"
      ]
    }
  },
  {
    "case_id": "case_21",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageHaveWorkedWith containing C# and ToolsTechHaveWorkedWith containing npm?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "185",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageHaveWorkedWith containing C# and ToolsTechHaveWorkedWith containing npm?",
      "matching_respondents": [
        "185"
      ]
    }
  },
  {
    "case_id": "case_22",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have ToolsTechHaveWorkedWith containing Kubernetes and LanguageHaveWorkedWith containing Go?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "213, 72773",
    "metadata": {
      "inference_question": "Which respondent numbers have ToolsTechHaveWorkedWith containing Kubernetes and LanguageHaveWorkedWith containing Go?",
      "matching_respondents": [
        "213",
        "72773"
      ]
    }
  },
  {
    "case_id": "case_23",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have MainBranch A and LanguageHaveWorkedWith containing Swift?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "73037",
    "metadata": {
      "inference_question": "Which respondent numbers have MainBranch A and LanguageHaveWorkedWith containing Swift?",
      "matching_respondents": [
        "73037"
      ]
    }
  },
  {
    "case_id": "case_24",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have MainBranch A and LanguageHaveWorkedWith containing PowerShell?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72805",
    "metadata": {
      "inference_question": "Which respondent numbers have MainBranch A and LanguageHaveWorkedWith containing PowerShell?",
      "matching_respondents": [
        "72805"
      ]
    }
  },
  {
    "case_id": "case_25",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCode of 22 and EdLevel E?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "73217",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCode of 22 and EdLevel E?",
      "matching_respondents": [
        "73217"
      ]
    }
  },
  {
    "case_id": "case_26",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have EdLevel C and LanguageWantToWorkWith containing HTML/CSS?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72663",
    "metadata": {
      "inference_question": "Which respondent numbers have EdLevel C and LanguageWantToWorkWith containing HTML/CSS?",
      "matching_respondents": [
        "72663"
      ]
    }
  },
  {
    "case_id": "case_27",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have MainBranch A and LanguageHaveWorkedWith containing SQL?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "106, 306, 511",
    "metadata": {
      "inference_question": "Which respondent numbers have MainBranch A and LanguageHaveWorkedWith containing SQL?",
      "matching_respondents": [
        "106",
        "306",
        "511"
      ]
    }
  },
  {
    "case_id": "case_28",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCodePro of 1 and Country Italy?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "None",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCodePro of 1 and Country Italy?",
      "matching_respondents": []
    }
  },
  {
    "case_id": "case_29",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCode of 10 and Country Iran, Islamic Republic of...?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "None",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCode of 10 and Country Iran, Islamic Republic of...?",
      "matching_respondents": []
    }
  },
  {
    "case_id": "case_30",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have VersionControlSystem A and DevType containing Developer, desktop or enterprise applications?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "29048",
    "metadata": {
      "inference_question": "Which respondent numbers have VersionControlSystem A and DevType containing Developer, desktop or enterprise applications?",
      "matching_respondents": [
        "29048"
      ]
    }
  },
  {
    "case_id": "case_31",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageHaveWorkedWith containing SQL and LanguageWantToWorkWith containing Kotlin?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72630",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageHaveWorkedWith containing SQL and LanguageWantToWorkWith containing Kotlin?",
      "matching_respondents": [
        "72630"
      ]
    }
  },
  {
    "case_id": "case_32",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageHaveWorkedWith containing Ruby and VersionControlSystem A?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "448",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageHaveWorkedWith containing Ruby and VersionControlSystem A?",
      "matching_respondents": [
        "448"
      ]
    }
  },
  {
    "case_id": "case_33",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have MainBranch A and LanguageHaveWorkedWith containing HTML/CSS?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72824",
    "metadata": {
      "inference_question": "Which respondent numbers have MainBranch A and LanguageHaveWorkedWith containing HTML/CSS?",
      "matching_respondents": [
        "72824"
      ]
    }
  },
  {
    "case_id": "case_34",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have DevType containing Developer, full-stack and VersionControlSystem A?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72835, 73107",
    "metadata": {
      "inference_question": "Which respondent numbers have DevType containing Developer, full-stack and VersionControlSystem A?",
      "matching_respondents": [
        "72835",
        "73107"
      ]
    }
  },
  {
    "case_id": "case_35",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have DevType containing Developer, full-stack and LanguageHaveWorkedWith containing Clojure?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "430",
    "metadata": {
      "inference_question": "Which respondent numbers have DevType containing Developer, full-stack and LanguageHaveWorkedWith containing Clojure?",
      "matching_respondents": [
        "430"
      ]
    }
  },
  {
    "case_id": "case_36",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageHaveWorkedWith containing JavaScript and LanguageWantToWorkWith containing SQL?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "238, 72725",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageHaveWorkedWith containing JavaScript and LanguageWantToWorkWith containing SQL?",
      "matching_respondents": [
        "238",
        "72725"
      ]
    }
  },
  {
    "case_id": "case_37",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have Country India and CompTotal of 500000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "None",
    "metadata": {
      "inference_question": "Which respondent numbers have Country India and CompTotal of 500000.0?",
      "matching_respondents": []
    }
  },
  {
    "case_id": "case_38",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have DevType containing Developer, full-stack and CompTotal of 950000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72710",
    "metadata": {
      "inference_question": "Which respondent numbers have DevType containing Developer, full-stack and CompTotal of 950000.0?",
      "matching_respondents": [
        "72710"
      ]
    }
  },
  {
    "case_id": "case_39",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have CompFreq C and LanguageWantToWorkWith containing TypeScript?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72751",
    "metadata": {
      "inference_question": "Which respondent numbers have CompFreq C and LanguageWantToWorkWith containing TypeScript?",
      "matching_respondents": [
        "72751"
      ]
    }
  },
  {
    "case_id": "case_40",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have CompFreq C and LanguageHaveWorkedWith containing Bash/Shell?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72659",
    "metadata": {
      "inference_question": "Which respondent numbers have CompFreq C and LanguageHaveWorkedWith containing Bash/Shell?",
      "matching_respondents": [
        "72659"
      ]
    }
  },
  {
    "case_id": "case_41",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have DevType containing Developer, front-end and CompTotal of 128000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72682",
    "metadata": {
      "inference_question": "Which respondent numbers have DevType containing Developer, front-end and CompTotal of 128000.0?",
      "matching_respondents": [
        "72682"
      ]
    }
  },
  {
    "case_id": "case_42",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageWantToWorkWith containing Java and VersionControlSystem A?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "213",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageWantToWorkWith containing Java and VersionControlSystem A?",
      "matching_respondents": [
        "213"
      ]
    }
  },
  {
    "case_id": "case_43",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageHaveWorkedWith containing HTML/CSS and LanguageWantToWorkWith containing Rust?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "242, 413, 72836",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageHaveWorkedWith containing HTML/CSS and LanguageWantToWorkWith containing Rust?",
      "matching_respondents": [
        "242",
        "413",
        "72836"
      ]
    }
  },
  {
    "case_id": "case_44",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have MainBranch A and DevType containing Cloud infrastructure engineer?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "386",
    "metadata": {
      "inference_question": "Which respondent numbers have MainBranch A and DevType containing Cloud infrastructure engineer?",
      "matching_respondents": [
        "386"
      ]
    }
  },
  {
    "case_id": "case_45",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCodePro of 5 and LanguageHaveWorkedWith containing TypeScript?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "409",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCodePro of 5 and LanguageHaveWorkedWith containing TypeScript?",
      "matching_respondents": [
        "409"
      ]
    }
  },
  {
    "case_id": "case_46",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageHaveWorkedWith containing SQL and LanguageWantToWorkWith containing Ruby?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "29045",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageHaveWorkedWith containing SQL and LanguageWantToWorkWith containing Ruby?",
      "matching_respondents": [
        "29045"
      ]
    }
  },
  {
    "case_id": "case_47",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have DevType containing Data or business analyst and ToolsTechHaveWorkedWith containing Terraform?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72955",
    "metadata": {
      "inference_question": "Which respondent numbers have DevType containing Data or business analyst and ToolsTechHaveWorkedWith containing Terraform?",
      "matching_respondents": [
        "72955"
      ]
    }
  },
  {
    "case_id": "case_48",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have DevType containing Senior Executive (C-Suite, VP, etc.) and CompFreq C?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "165",
    "metadata": {
      "inference_question": "Which respondent numbers have DevType containing Senior Executive (C-Suite, VP, etc.) and CompFreq C?",
      "matching_respondents": [
        "165"
      ]
    }
  },
  {
    "case_id": "case_49",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have YearsCode of 43 and LanguageHaveWorkedWith containing Bash/Shell?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "479",
    "metadata": {
      "inference_question": "Which respondent numbers have YearsCode of 43 and LanguageHaveWorkedWith containing Bash/Shell?",
      "matching_respondents": [
        "479"
      ]
    }
  },
  {
    "case_id": "case_50",
    "task": "multi_hop_relational_inference",
    "CASE_1": "Which respondent numbers have YearsCodePro of 18 and CompTotal of 280000.0?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 29115",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "Which respondent numbers have LanguageWantToWorkWith containing Erlang and CompFreq B?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<request>\nBefore providing final answer, please [REQUEST]\n</request>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": "72720",
    "metadata": {
      "inference_question": "Which respondent numbers have LanguageWantToWorkWith containing Erlang and CompFreq B?",
      "matching_respondents": [
        "72720"
      ]
    }
  }
]