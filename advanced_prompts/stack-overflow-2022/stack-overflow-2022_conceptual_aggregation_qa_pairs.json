[
  {
    "case_id": "case_1",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have MainBranch A?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 8,
    "metadata": {
      "aggregation_question": "How many respondents have MainBranch A?",
      "count": 8,
      "category_type": "identity_analysis"
    }
  },
  {
    "case_id": "case_2",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageWantToWorkWith Go;Python;Rust;Scala?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageWantToWorkWith Go;Python;Rust;Scala?",
      "count": 1,
      "category_type": "education_analysis"
    }
  },
  {
    "case_id": "case_3",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCodePro 15?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCodePro 15?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_4",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have Country United States of America?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have Country United States of America?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_5",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have CompFreq C?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 4,
    "metadata": {
      "aggregation_question": "How many respondents have CompFreq C?",
      "count": 4,
      "category_type": "compensation_analysis"
    }
  },
  {
    "case_id": "case_6",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have Employment A?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 4,
    "metadata": {
      "aggregation_question": "How many respondents have Employment A?",
      "count": 4,
      "category_type": "employment_analysis"
    }
  },
  {
    "case_id": "case_7",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have VersionControlSystem A?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 4,
    "metadata": {
      "aggregation_question": "How many respondents have VersionControlSystem A?",
      "count": 4,
      "category_type": "tool_analysis"
    }
  },
  {
    "case_id": "case_8",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCode 8?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCode 8?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_9",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have EdLevel E?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 6,
    "metadata": {
      "aggregation_question": "How many respondents have EdLevel E?",
      "count": 6,
      "category_type": "education_analysis"
    }
  },
  {
    "case_id": "case_10",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have Country Brazil?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have Country Brazil?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_11",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have OrgSize 100 to 499 employees?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have OrgSize 100 to 499 employees?",
      "count": 1,
      "category_type": "organization_analysis"
    }
  },
  {
    "case_id": "case_12",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCodePro 10?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCodePro 10?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_13",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have EdLevel F?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have EdLevel F?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_14",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have CompFreq B?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 2,
    "metadata": {
      "aggregation_question": "How many respondents have CompFreq B?",
      "count": 2,
      "category_type": "compensation_analysis"
    }
  },
  {
    "case_id": "case_15",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageWantToWorkWith C;C++;Python;Rust?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageWantToWorkWith C;C++;Python;Rust?",
      "count": 1,
      "category_type": "education_analysis"
    }
  },
  {
    "case_id": "case_16",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have Country Luxembourg?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have Country Luxembourg?",
      "count": 1,
      "category_type": "organization_analysis"
    }
  },
  {
    "case_id": "case_17",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have CompTotal 120000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have CompTotal 120000.0?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_18",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageHaveWorkedWith C#;C++;HTML/CSS;Java;JavaScript;Kotlin;PHP;SQL;TypeScript;VBA?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageHaveWorkedWith C#;C++;HTML/CSS;Java;JavaScript;Kotlin;PHP;SQL;TypeScript;VBA?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_19",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCodePro 8?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCodePro 8?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_20",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCodePro 11?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCodePro 11?",
      "count": 1,
      "category_type": "organization_analysis"
    }
  },
  {
    "case_id": "case_21",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have DevType Developer, back-end;DevOps specialist;Cloud infrastructure engineer;System administrator?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have DevType Developer, back-end;DevOps specialist;Cloud infrastructure engineer;System administrator?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_22",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCodePro 1?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCodePro 1?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_23",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageHaveWorkedWith Bash/Shell;C#;Python;SQL?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageHaveWorkedWith Bash/Shell;C#;Python;SQL?",
      "count": 1,
      "category_type": "education_analysis"
    }
  },
  {
    "case_id": "case_24",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have EdLevel E?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 2,
    "metadata": {
      "aggregation_question": "How many respondents have EdLevel E?",
      "count": 2,
      "category_type": "organization_analysis"
    }
  },
  {
    "case_id": "case_25",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCodePro 14?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCodePro 14?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_26",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCode 3?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCode 3?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_27",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have EdLevel F?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have EdLevel F?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_28",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have OrgSize 500 to 999 employees?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 2,
    "metadata": {
      "aggregation_question": "How many respondents have OrgSize 500 to 999 employees?",
      "count": 2,
      "category_type": "organization_analysis"
    }
  },
  {
    "case_id": "case_29",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have DevType Data scientist or machine learning specialist;Engineer, data;Data or business analyst?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have DevType Data scientist or machine learning specialist;Engineer, data;Data or business analyst?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_30",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have DevType Developer, back-end;DevOps specialist?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have DevType Developer, back-end;DevOps specialist?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_31",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have DevType Developer, front-end;Developer, full-stack?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have DevType Developer, front-end;Developer, full-stack?",
      "count": 1,
      "category_type": "education_analysis"
    }
  },
  {
    "case_id": "case_32",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageWantToWorkWith HTML/CSS;Java;JavaScript;Kotlin;TypeScript?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageWantToWorkWith HTML/CSS;Java;JavaScript;Kotlin;TypeScript?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_33",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have OrgSize 10 to 19 employees?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have OrgSize 10 to 19 employees?",
      "count": 1,
      "category_type": "organization_analysis"
    }
  },
  {
    "case_id": "case_34",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCodePro 4?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCodePro 4?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_35",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have ToolsTechHaveWorkedWith Ansible;Docker;Kubernetes;Terraform?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have ToolsTechHaveWorkedWith Ansible;Docker;Kubernetes;Terraform?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_36",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCode 7?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCode 7?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_37",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCode 40?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCode 40?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_38",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have Country Portugal?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have Country Portugal?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_39",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have ToolsTechHaveWorkedWith Docker;Terraform?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have ToolsTechHaveWorkedWith Docker;Terraform?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_40",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageWantToWorkWith C#;HTML/CSS;JavaScript;Python;TypeScript?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageWantToWorkWith C#;HTML/CSS;JavaScript;Python;TypeScript?",
      "count": 1,
      "category_type": "organization_analysis"
    }
  },
  {
    "case_id": "case_41",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have CompTotal 110000.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have CompTotal 110000.0?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_42",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCode 15?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 2,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCode 15?",
      "count": 2,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_43",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageHaveWorkedWith Assembly;C;PHP;Python;R;SQL?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageHaveWorkedWith Assembly;C;PHP;Python;R;SQL?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_44",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have OrgSize 20 to 99 employees?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have OrgSize 20 to 99 employees?",
      "count": 1,
      "category_type": "organization_analysis"
    }
  },
  {
    "case_id": "case_45",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have EdLevel C?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have EdLevel C?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_46",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have DevType Senior Executive (C-Suite, VP, etc.)?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have DevType Senior Executive (C-Suite, VP, etc.)?",
      "count": 1,
      "category_type": "geographic_analysis"
    }
  },
  {
    "case_id": "case_47",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageWantToWorkWith C++;Python;Rust?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageWantToWorkWith C++;Python;Rust?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_48",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have LanguageWantToWorkWith C++;HTML/CSS;JavaScript;Python?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have LanguageWantToWorkWith C++;HTML/CSS;JavaScript;Python?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_49",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have YearsCodePro 11?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have YearsCodePro 11?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  },
  {
    "case_id": "case_50",
    "task": "conceptual_aggregation",
    "CASE_1": "How many respondents have MainBranch A?\n\nDATA:\n\n[Insert the full data block here]\n\nAnswer: 8",
    "questionnaire": "[Insert the full data block here]",
    "ROLE_PROMPTING": "You are a meticulous data analyst AI. Your primary function is to accurately analyze structured data and provide precise, verifiable answers.",
    "FORMAT_EXPLANATION": "You will be given a dataset with two key parts:\n\nA 'questions' section: This is your data dictionary or schema. It is the single source of truth for understanding what each field and score means. Refer to it carefully.\n\nA 'responses' section: This contains the raw data from each individual respondent.\n\nTo answer the question correctly, you must first use the 'questions' schema to fully understand the context and meaning of the data points within the 'responses'. Do not rely on any prior knowledge outside of this provided data. Base your entire analysis on the information given.",
    "OUTPUT_INSTRUCTIONS": "Provide your final answer directly and concisely. Output must be the human-readable value, not an option code.\n\nRules:\n- For MCQ fields, map any letter codes in the Responses (case-insensitive) to the corresponding option text from the Questions schema, and output only that text. Do NOT include the letter or both.\n  Example: If the schema is \"[MCQ: A. Abnormal B. Inconclusive C. Normal]\" and the response is \"a\", output \"Abnormal\".\n- For open-ended fields, output the exact text value.\n- If the question asks for a count, provide only the number (e.g., \"42\").\n- If the question asks for a list of names or IDs, provide a simple comma-separated list (e.g., \"17, 21, 23\").\n- Preserve capitalization exactly as in the schema (e.g., output \"Abnormal\", not \"abnormal\" or \"A\").",
    "question": "How many respondents have CompTotal 96300.0?",
    "prompt": "<example>\n[CASE_1]\n</example>\n\n<questionnaire>\n[questionnaire]\n</questionnaire>\n\n<role>\n[ROLE_PROMPTING]\n\n</role>\n\n<format>\n[FORMAT_EXPLANATION]\n\n</format>\n\n<output>\n[OUTPUT_INSTRUCTIONS]\n\n</output>\n\n<task>\n[question]\n</task>",
    "expected_answer": 1,
    "metadata": {
      "aggregation_question": "How many respondents have CompTotal 96300.0?",
      "count": 1,
      "category_type": "experience_analysis"
    }
  }
]