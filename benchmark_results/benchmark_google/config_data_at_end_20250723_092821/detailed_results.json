{
  "healthcare-dataset/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5494105815887451,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:22.408052"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5180373191833496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:22.931051"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.090285301208496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:24.025625"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4065821170806885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:24.437541"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3861877918243408,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:24.828975"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4553384780883789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:25.290347"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3919234275817871,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:25.686239"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5311896800994873,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:26.222593"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3353612422943115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:26.562952"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5032453536987305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:27.071177"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37098264694213867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:27.446160"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38042521476745605,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:27.830759"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36382532119750977,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:28.199617"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3849475383758545,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:28.589563"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3546268939971924,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:28.958522"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3433544635772705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:29.308878"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3455030918121338,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:29.659384"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.389268159866333,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:30.055632"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.445019006729126,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:30.510649"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9514813423156738,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:31.681136"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0652940273284912,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:32.756598"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.528022289276123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:33.381622"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7580893039703369,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:34.160942"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6483316421508789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:34.820784"
    }
  ],
  "healthcare-dataset/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5492219924926758,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:35.383698"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47240447998046875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:35.862102"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4823455810546875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:36.354080"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4549906253814697,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:36.825630"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4934992790222168,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:37.332080"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6451325416564941,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:38.032908"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6149251461029053,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:38.654824"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46451330184936523,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:39.132523"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6654541492462158,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:39.825972"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5932888984680176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:40.430259"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4785032272338867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:40.914739"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.573533296585083,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:42.499982"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.914684772491455,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:44.429703"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44638681411743164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:44.888071"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6843321323394775,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:45.584070"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.495286226272583,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:46.090027"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6358127593994141,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:46.730870"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4701368808746338,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:47.206003"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8754105567932129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:48.092393"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8543429374694824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:48.957014"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.63142728805542,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:50.602439"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1741538047790527,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:51.789575"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39835548400878906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:52.200914"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4301581382751465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:52.643239"
    }
  ],
  "healthcare-dataset/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5833735466003418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:53.248661"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.409163236618042,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:53.666830"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41253066062927246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:54.089621"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4709131717681885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:54.569057"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5977795124053955,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:55.174814"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49363183975219727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:55.679464"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5054981708526611,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:56.277968"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37082767486572266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:56.674801"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6600217819213867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:57.349387"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3817322254180908,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:57.736120"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36582064628601074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:58.106885"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4856405258178711,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:58.596417"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5219221115112305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:59.129684"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3779761791229248,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:28:59.520051"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0195353031158447,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:00.553145"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.626795768737793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:01.211273"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6194639205932617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:01.859740"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4456212520599365,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:02.330679"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49738407135009766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:02.844072"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37178945541381836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:03.236929"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2410697937011719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:04.773443"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5582489967346191,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:05.421396"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7095053195953369,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:06.154916"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7414546012878418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:06.912356"
    }
  ],
  "healthcare-dataset/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5118148326873779,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:07.453171"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1495723724365234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:08.616586"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44245076179504395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:09.073372"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41553425788879395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:09.504508"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6727771759033203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:10.193219"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4349329471588135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:10.644253"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4205513000488281,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:11.080382"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3859529495239258,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:11.479691"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3722364902496338,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:11.862972"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8466122150421143,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:12.719119"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44223594665527344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:13.177615"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4048023223876953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:13.598040"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6237087249755859,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:14.235108"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5629653930664062,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:14.810140"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40379762649536133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:15.225612"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3940553665161133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:15.634188"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5443198680877686,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:16.190379"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39931464195251465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:16.599461"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "43",
      "llm_response": "33",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4393172264099121,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:17.050771"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "43",
      "llm_response": "33",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.661630392074585,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:17.724603"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3635284900665283,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:18.101809"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "43",
      "llm_response": "33",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44879651069641113,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:18.564865"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.496126651763916,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:19.072097"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "43",
      "llm_response": "33",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.188852071762085,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:20.275089"
    }
  ],
  "healthcare-dataset/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6159281730651855,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:20.915258"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5987997055053711,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:21.530067"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5604102611541748,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:22.106464"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.578707218170166,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:22.696185"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5015673637390137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:24.211042"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6911413669586182,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:24.913620"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "7",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5471794605255127,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:25.475113"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45650696754455566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:25.945665"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39214563369750977,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:26.352796"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42847204208374023,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:26.796036"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44313645362854004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:27.255760"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4366037845611572,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:27.707353"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5032913684844971,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:28.227302"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7672591209411621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:29.011543"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41663098335266113,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:29.450183"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42949724197387695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:29.899641"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.5090370178222656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:32.427895"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 5.487107992172241,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:37.929986"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 3.7916159629821777,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:41.736969"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4861657619476318,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:43.243104"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 7.836568832397461,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:51.097795"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 4.927599668502808,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:56.046394"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.1496901512145996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:58.213600"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5510852336883545,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:58.781512"
    }
  ],
  "healthcare-dataset/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "2, 4, 5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.648665189743042,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:29:59.458477"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94,39,90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3754632472991943,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:00.850936"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.620037317276001,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:01.487561"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5657823085784912,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:02.074328"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4479959011077881,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:02.538326"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.558485984802246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:04.109809"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8891289234161377,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:05.016404"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42977237701416016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:05.458615"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 3.2088611125946045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:08.684225"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5173006057739258,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:09.410540"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.283360481262207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:10.705653"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4584674835205078,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:11.179646"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 5.015415191650391,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:16.212462"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4275081157684326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:16.659993"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47675395011901855,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:17.151785"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.8107800483703613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:18.984537"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.7178685665130615,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:21.736904"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4370920658111572,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:23.191991"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "3, 5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 4.226612329483032,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:27.433566"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.8161158561706543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:29.264701"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0432462692260742,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:30.325972"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6002500057220459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:30.946257"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.0087060928344727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:32.969000"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.874854326248169,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:35.860840"
    }
  ],
  "isbar/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 3.7029500007629395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:40.271870"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3042635917663574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:41.591148"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40912318229675293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:42.018272"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.0671262741088867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:44.106085"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48358631134033203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:44.612711"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7913241386413574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:45.424441"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.7983262538909912,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:47.241703"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3668172359466553,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:48.625505"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5464117527008057,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:49.189927"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4680619239807129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:49.669202"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.260986089706421,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:51.949937"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2446744441986084,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:53.208832"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4228930473327637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:54.646725"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4285030364990234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:56.100470"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6173200607299805,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:57.737774"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6439664363861084,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:58.399087"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5560872554779053,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:30:58.975172"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1925899982452393,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:00.181761"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.0757946968078613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:02.276581"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8379461765289307,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:03.134927"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6615352630615234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:03.816475"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0551798343658447,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:04.887577"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4522972106933594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:05.354814"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5156564712524414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:05.890438"
    }
  ],
  "isbar/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.1196229457855225,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:08.033057"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4840381145477295,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:08.533065"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3812217712402344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:08.927531"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42926621437072754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:09.381498"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39445948600769043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:09.792441"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47071361541748047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:10.279264"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39800310134887695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:10.693812"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4102916717529297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:11.122873"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3465158939361572,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:11.488665"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38721680641174316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:11.887939"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0154690742492676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:12.918972"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5063369274139404,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:13.444322"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6242527961730957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:14.089171"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7760117053985596,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:14.890198"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8241121768951416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:15.731319"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45038771629333496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:16.197720"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.1667020320892334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:18.379388"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.566270351409912,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:19.961891"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2108824253082275,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:21.188763"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6930675506591797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:21.903873"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.305173635482788,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:23.228052"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6767539978027344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:23.951548"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44841504096984863,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:24.416690"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7864303588867188,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:25.214393"
    }
  ],
  "isbar/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4002399444580078,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:25.657469"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.606170654296875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:26.280953"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6388030052185059,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:26.937737"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.608189582824707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:27.562999"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7900128364562988,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:28.371999"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4771134853363037,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:28.871628"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8244950771331787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:29.711591"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41330409049987793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:30.142891"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39919328689575195,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:30.559517"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42231202125549316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:30.999518"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4196619987487793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:31.436101"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.1594300270080566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:33.616605"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7859354019165039,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:34.418243"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44399142265319824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:34.877587"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3803439140319824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:35.273728"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40686726570129395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:35.691140"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3737020492553711,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:36.078811"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41751599311828613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:36.512349"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.323535680770874,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:37.856893"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5461626052856445,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:38.586531"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.625960111618042,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:39.229999"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4839620590209961,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:39.739306"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5503396987915039,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:40.308628"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3406872749328613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:41.665305"
    }
  ],
  "isbar/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1799757480621338,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:42.875540"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.496304988861084,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:43.390486"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4366786479949951,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:43.845197"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0824120044708252,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:44.952645"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6184563636779785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:45.587100"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42671656608581543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:46.031819"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.178830623626709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:47.227638"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "21",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4014863967895508,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:47.652103"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "21",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7038533687591553,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:48.376366"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3940396308898926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:48.790607"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33740901947021484,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:49.143567"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3981802463531494,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:49.558732"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.439802885055542,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:50.014718"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41837000846862793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:50.448867"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3736729621887207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:50.836547"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41481447219848633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:51.269040"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1414179801940918,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:52.429482"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42414021492004395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:52.873412"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19,11,6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45235514640808105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:53.344752"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19,11,6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5271730422973633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:53.888918"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19,11,6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4372737407684326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:54.438409"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19,11,6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5806303024291992,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:55.041054"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19,11,6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38433265686035156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:55.444388"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "6,11,19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6868624687194824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:56.147238"
    }
  ],
  "isbar/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5244660377502441,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:56.690130"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36521267890930176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:57.072359"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3268420696258545,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:57.419400"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5337052345275879,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:57.971144"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8325521945953369,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:58.833888"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0910701751708984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:31:59.941549"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 10,
      "llm_response": "12",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5116021633148193,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:01.472140"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5013606548309326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:02.987236"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 10,
      "llm_response": "13",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6235513687133789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:03.620961"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8848755359649658,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:04.521850"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4171886444091797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:05.961045"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 10,
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5135953426361084,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:06.492669"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5179851055145264,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:07.031221"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9024820327758789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:07.949688"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2319750785827637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:09.197639"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4774961471557617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:09.697441"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.221635341644287,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:10.934085"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38808155059814453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:11.339199"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4389986991882324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:11.923656"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37727952003479004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:12.328944"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2552978992462158,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:13.604242"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.421053409576416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:14.047279"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35630106925964355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:14.424614"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3624539375305176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:14.804064"
    }
  ],
  "isbar/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4583890438079834,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:15.290296"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46595311164855957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:15.776412"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40560388565063477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:16.203003"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5247194766998291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:16.745734"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4266235828399658,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:17.193674"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.073606252670288,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:18.284334"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6136987209320068,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:18.914041"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6123988628387451,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:19.543417"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0694210529327393,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:20.634852"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.4857301712036133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:23.139841"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.3601150512695312,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:25.517941"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6032049655914307,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:26.142652"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5764124393463135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:26.739989"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6840922832489014,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:27.448320"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6571850776672363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:28.122663"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5975356101989746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:28.738200"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4497518539428711,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:29.212169"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7324626445770264,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:29.957614"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40637993812561035,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:30.379006"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4741649627685547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:30.875157"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41399145126342773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:31.308705"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4529125690460205,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:31.785307"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47427940368652344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:32.278598"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41358041763305664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\isbar\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:32.708156"
    }
  ],
  "self-reported-mental-health-college-students-2022/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6554965972900391,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:33.403287"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.533571720123291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:33.959695"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6999573707580566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:34.716262"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5404860973358154,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:36.273738"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7783138751983643,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:37.111037"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5968837738037109,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:37.728087"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5868256092071533,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:38.327558"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4455747604370117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:38.790440"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8921778202056885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:39.702677"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6943209171295166,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:40.412005"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5959248542785645,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:41.023807"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3942477703094482,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:42.434050"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2168021202087402,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:43.669968"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.23685622215271,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:44.925611"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8206126689910889,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:45.762218"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6179287433624268,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:46.404301"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9586663246154785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:47.379364"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.9088258743286133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:49.306191"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.513425350189209,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:50.843578"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9545445442199707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:51.890235"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7331430912017822,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:52.644380"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6475503444671631,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:53.316236"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6450645923614502,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:53.987231"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.819124460220337,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:55.831357"
    }
  ],
  "self-reported-mental-health-college-students-2022/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6001472473144531,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:56.473592"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4365406036376953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:56.929150"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.36665678024292,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:58.311989"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5796933174133301,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:32:58.916822"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1633074283599854,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:00.104094"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8421792984008789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:00.964268"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.7223856449127197,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:02.707090"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5197708606719971,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:03.340019"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9445114135742188,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:04.301412"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7080116271972656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:05.025999"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8476569652557373,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:05.891242"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6369218826293945,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:06.546716"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0691096782684326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:07.632746"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5622906684875488,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:08.213010"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6485195159912109,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:08.880537"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8488528728485107,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:09.744648"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.947777271270752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:10.711460"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5089735984802246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:12.236421"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18,4,134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6433141231536865,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:12.902774"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18,4,134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8269021511077881,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:13.755619"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18,4,134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6544597148895264,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:14.434025"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18,4,134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0440127849578857,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:15.507063"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18,4,134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6837081909179688,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:17.205785"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18,4,134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.81479811668396,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:18.042563"
    }
  ],
  "self-reported-mental-health-college-students-2022/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6561036109924316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:18.731317"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7774953842163086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:19.532823"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9660751819610596,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:20.524859"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.479954481124878,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:22.033512"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6014442443847656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:22.654113"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3726608753204346,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:24.056889"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.2112581729888916,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:26.292995"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3634884357452393,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:27.673940"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0580613613128662,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:28.749760"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 3.9112565517425537,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:32.685053"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9326002597808838,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:33.644632"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5377223491668701,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:34.218724"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0912506580352783,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:35.323448"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 3.418238878250122,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:38.791664"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.1458890438079834,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:40.949675"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.68971848487854,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:41.651634"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9563815593719482,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:42.618760"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4949944019317627,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:43.124756"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5032782554626465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:43.660371"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7266364097595215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:44.393998"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5970921516418457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:45.005366"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6198670864105225,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:45.637712"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8899872303009033,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:46.541135"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.538724422454834,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:47.096217"
    }
  ],
  "self-reported-mental-health-college-students-2022/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.8064665794372559,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:48.916682"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8883335590362549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:49.821891"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1695091724395752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:50.995400"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.5039665699005127,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:53.505518"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7515804767608643,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:54.263095"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5556635856628418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:54.823720"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29",
      "llm_response": "82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.014328956604004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:55.844244"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29",
      "llm_response": "82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44380712509155273,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:56.293657"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29",
      "llm_response": "82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.717193603515625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:57.014851"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29",
      "llm_response": "82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6379890441894531,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:57.658061"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29",
      "llm_response": "82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5753006935119629,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:58.237540"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29",
      "llm_response": "82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5512509346008301,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:58.793698"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.045445203781128,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:33:59.843909"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.578794002532959,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:00.427424"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.690190315246582,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:01.121915"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6534192562103271,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:02.783143"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8838090896606445,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:03.670704"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5759665966033936,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:04.251362"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.076615571975708,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:05.332736"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4598655700683594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:05.797336"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6719968318939209,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:06.475467"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0046679973602295,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:07.485403"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6940708160400391,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:08.184763"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5975217819213867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:09.786511"
    }
  ],
  "self-reported-mental-health-college-students-2022/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.972853422164917,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:11.766544"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5986196994781494,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:12.371707"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6996884346008301,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:13.075877"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.902266263961792,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:13.983348"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8820397853851318,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:14.871194"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1994946002960205,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:16.074686"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.595268964767456,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:16.679368"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.9908409118652344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:18.675230"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2825028896331787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:19.964118"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.974536657333374,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:20.944627"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5940456390380859,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:21.543637"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5159580707550049,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:22.068440"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8187065124511719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:22.893005"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6022069454193115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:23.500224"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5876796245574951,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:24.091905"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1880309581756592,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:25.284937"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.768455982208252,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:26.056393"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.031130313873291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:27.091614"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8339312076568604,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:27.930541"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5115196704864502,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:28.446793"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5740616321563721,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:29.025668"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7951643466949463,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:29.827308"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6258101463317871,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:30.457316"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6610243320465088,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:31.122569"
    }
  ],
  "self-reported-mental-health-college-students-2022/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49536752700805664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:31.625081"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.566190242767334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:32.194384"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8039629459381104,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:33.006422"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.575023889541626,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:35.586544"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2106585502624512,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:36.803376"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "No respondents provided data.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5880553722381592,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:38.396662"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4037034511566162,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:38.806835"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6967084407806396,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:39.509701"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0454611778259277,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:40.560544"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "None",
      "llm_response": "53",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1143178939819336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:41.678855"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.816490650177002,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:42.500251"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "None",
      "llm_response": "There is no data in the provided XML to answer the question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.66802978515625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:43.173281"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.7801930904388428,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:44.958831"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7102711200714111,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:45.674213"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.0117197036743164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:47.691312"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7773323059082031,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:48.473357"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.58392333984375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:49.062426"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "No answer.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4617829322814941,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:50.529031"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "66",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5897090435028076,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:51.121739"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 110, 131, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6274352073669434,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:51.753176"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 110, 131, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7517752647399902,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:52.510442"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 110, 131, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7570364475250244,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:53.272769"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 110, 131, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8595108985900879,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:54.136121"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "Answer:",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5950438976287842,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:54.736135"
    }
  ],
  "stack-overflow-2022-developer-survey/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48331785202026367,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:55.228339"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 3.0610384941101074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:34:58.294532"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.3847522735595703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:00.687660"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8714184761047363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:01.567229"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.8784050941467285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:03.449653"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1750226020812988,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:04.630688"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3214130401611328,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:05.955909"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0867445468902588,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:07.046662"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9641275405883789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:08.015793"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1527316570281982,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:09.173522"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6936545372009277,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:09.874080"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.513150691986084,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:10.391230"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41557741165161133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:10.812709"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49878668785095215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:11.314622"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0690250396728516,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:12.387588"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3959708213806152,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:13.790560"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4812746047973633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:14.276081"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9015352725982666,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:15.181070"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5437576770782471,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:15.728842"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3881697654724121,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:16.120969"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5244884490966797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:16.650491"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1764652729034424,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:17.830596"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9370074272155762,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:18.772614"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6235182285308838,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:19.400132"
    }
  ],
  "stack-overflow-2022-developer-survey/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5671374797821045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:19.973684"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49685192108154297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:20.476673"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46563196182250977,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:20.946439"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.2887539863586426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:23.241418"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5669164657592773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:23.812344"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5638744831085205,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:24.380226"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5173695087432861,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:24.901594"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102,73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6198642253875732,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:26.526547"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.705437421798706,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:28.235975"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0802223682403564,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:29.321535"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.550823450088501,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:29.876347"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5247645378112793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:30.406083"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.608051061630249,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:31.017327"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382,29109,123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6459496021270752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:31.666496"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382,29109,123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8015303611755371,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:32.475927"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382,29109,123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8246006965637207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:33.306847"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4584541320800781,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:34.770710"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382,29109,123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6205112934112549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:35.394574"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740,409,73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.0087342262268066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:37.407368"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740,409,73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.8195042610168457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:39.231849"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740,409,73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5158038139343262,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:39.754571"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740,409,73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8569049835205078,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:40.619214"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740,409,73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9820835590362549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:41.606088"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740,409,73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5836727619171143,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:42.194535"
    }
  ],
  "stack-overflow-2022-developer-survey/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9219181537628174,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:43.125440"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.518585205078125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:43.648147"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 3.3570964336395264,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:47.009239"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.833132028579712,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:49.846367"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.024599313735962,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:50.876963"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6419634819030762,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:51.523089"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5709843635559082,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:53.101857"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4335041046142578,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:53.539338"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5175750255584717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:55.064376"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1995525360107422,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:56.267925"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.1432955265045166,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:58.414366"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.538341760635376,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:58.982697"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8408446311950684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:35:59.869809"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45819616317749023,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:00.339030"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4969148635864258,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:00.840947"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.7313013076782227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:02.575250"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47917771339416504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:03.057551"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4902307987213135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:03.553309"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5574395656585693,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:04.114749"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46272850036621094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:04.581870"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5060403347015381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:05.090910"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0357742309570312,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:06.131684"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8948304653167725,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:07.041271"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5379204750061035,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:07.601283"
    }
  ],
  "stack-overflow-2022-developer-survey/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8301296234130859,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:08.458959"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.688723087310791,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:09.160870"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.820115327835083,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:10.000678"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4611122608184814,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:11.906869"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5857818126678467,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:12.510638"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3360354900360107,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:13.864694"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0017025470733643,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:14.880399"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2213735580444336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:16.118781"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.695383310317993,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:18.830206"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7360424995422363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:19.582198"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.912893056869507,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:22.513085"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.9382882118225098,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:25.477932"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.688220739364624,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:26.182470"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7604737281799316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:26.954945"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45776820182800293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:27.422706"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43729305267333984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:27.877919"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5391192436218262,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:28.433046"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5448765754699707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:28.992737"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5206732749938965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:29.527747"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3859522342681885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:29.933945"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.259955883026123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:31.209960"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6286454200744629,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:31.855890"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4008660316467285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:32.272753"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47816967964172363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:32.769875"
    }
  ],
  "stack-overflow-2022-developer-survey/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7344872951507568,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:33.534825"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4920823574066162,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:34.045121"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8543853759765625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:34.917203"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3363404273986816,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:36.268373"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5502822399139404,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:36.835289"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6486399173736572,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:38.495940"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6308474540710449,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:39.147839"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7174434661865234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:39.881625"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5043606758117676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:40.404966"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5611751079559326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:40.980266"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5450730323791504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:41.541334"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8536355495452881,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:42.410974"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4100933074951172,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:42.836388"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4443328380584717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:43.295773"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4341428279876709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:43.743105"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5892224311828613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:44.340309"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40460824966430664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:44.760931"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6239550113677979,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:46.389881"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0505006313323975,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:47.447007"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6915855407714844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:48.149570"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8315000534057617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:49.002098"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8680055141448975,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:50.113096"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6198647022247314,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:51.883936"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5388984680175781,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:52.433814"
    }
  ],
  "stack-overflow-2022-developer-survey/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159,72969,208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8419365882873535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:53.300249"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159,72969,208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9157941341400146,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:54.230310"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159,72969,208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5639388561248779,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:54.810825"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159,72969,208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1853904724121094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:56.015299"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159,72969,208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.692561149597168,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:57.731641"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159,72969,208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5695066452026367,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:58.315504"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1873104572296143,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:36:59.516209"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7661426067352295,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:00.303571"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.590996265411377,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:00.909964"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1740448474884033,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:02.098287"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.608177661895752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:02.722038"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7211425304412842,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:03.457453"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5773744583129883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:04.050024"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9886901378631592,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:05.050032"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0210776329040527,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:06.089442"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4991014003753662,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:06.602926"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4937920570373535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:07.107696"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5417120456695557,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:07.659805"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7813258171081543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:08.452137"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4301743507385254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:08.898586"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4669528007507324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:09.377891"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8052108287811279,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:10.198854"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.9461545944213867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:12.158742"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7319867610931396,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:12.907734"
    }
  ],
  "sus-uta7/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7676723003387451,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:13.703791"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44864916801452637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:14.168439"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41667819023132324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:14.603097"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6048259735107422,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:16.224129"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6352965831756592,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:16.878427"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8015632629394531,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:17.698014"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4362449645996094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:18.150251"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.51096510887146,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:18.678222"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8880617618560791,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:19.582594"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5649454593658447,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:20.163533"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5643317699432373,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:20.743884"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8529806137084961,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:21.611639"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2343616485595703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:22.861198"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3134291172027588,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:24.222612"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.60270094871521,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:24.909311"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5934858322143555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:25.515305"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3761734962463379,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:25.899476"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37645506858825684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:26.280908"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1914279460906982,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:27.477361"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4732799530029297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:27.965619"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34043002128601074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:28.313519"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6349937915802002,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:28.968512"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.666907787322998,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:29.655417"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7348055839538574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:30.410135"
    }
  ],
  "sus-uta7/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8092837333679199,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:31.375501"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3739995956420898,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:32.819532"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7041807174682617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:33.537693"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7082347869873047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:34.263053"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.337249517440796,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:35.637606"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6242668628692627,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:36.286446"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40378403663635254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:36.707877"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4482102394104004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:37.188654"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7468922138214111,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:37.945549"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5063350200653076,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:38.475870"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3952960968017578,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:38.889138"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.514415979385376,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:39.417576"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4113459587097168,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:39.839256"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5513706207275391,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:40.406759"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8253781795501709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:41.247547"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5389328002929688,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:41.801463"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.646510124206543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:42.464962"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4437565803527832,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:42.930721"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6472809314727783,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:43.597613"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.026474952697754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:45.641065"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.3030991554260254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:47.965163"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4639570713043213,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:48.456533"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4282541275024414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:48.914941"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4493277072906494,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:49.378358"
    }
  ],
  "sus-uta7/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4419379234313965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:49.839028"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40344715118408203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:50.256764"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.506925106048584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:50.777702"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5229363441467285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:51.317052"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42136359214782715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:51.753481"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40668272972106934,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:52.172168"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37549376487731934,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:52.566684"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.164022207260132,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:54.756211"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5029547214508057,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:55.282159"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4011068344116211,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:55.699244"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3554549217224121,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:56.070065"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3885314464569092,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:56.471602"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3892691135406494,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:56.875842"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3693277835845947,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:57.251155"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4225802421569824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:57.679764"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3865067958831787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:58.083816"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6395514011383057,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:58.758101"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3900489807128906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:59.153572"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3701038360595703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:59.529768"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.426440954208374,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:37:59.967209"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34313178062438965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:00.327214"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7126171588897705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:01.046257"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34000229835510254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:01.399907"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3846902847290039,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:01.800565"
    }
  ],
  "sus-uta7/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4139866828918457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:02.292808"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5600042343139648,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:03.012812"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3992888927459717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:03.467099"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6638317108154297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:04.146974"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4345247745513916,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:05.616434"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48500609397888184,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:06.109471"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5023398399353027,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:07.848809"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4710538387298584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:08.325870"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.238626003265381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:10.577457"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7665724754333496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:11.355601"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4583888053894043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:11.820967"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4603402614593506,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:12.298306"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7844328880310059,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:13.110708"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24,61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0481746196746826,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:14.172879"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.308840036392212,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:15.499750"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8118972778320312,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:16.327088"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5855464935302734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:16.924010"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24,61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.837517499923706,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:17.776530"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4477217197418213,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:18.243561"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6208148002624512,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:19.880016"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.453279972076416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:20.348298"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5224246978759766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:20.887168"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43346548080444336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:21.328689"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47774672508239746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:21.821810"
    }
  ],
  "sus-uta7/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7675824165344238,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:22.636428"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4070727825164795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:23.067492"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7844886779785156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:23.870454"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0721564292907715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:24.958083"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5420897006988525,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:25.512186"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0444815158843994,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:26.570856"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45028257369995117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:27.032447"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7975902557373047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:27.844049"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38826608657836914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:28.245360"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4445061683654785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:28.700032"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36504268646240234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:29.082035"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4589529037475586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:29.558368"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4059774875640869,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:29.981345"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40110278129577637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:30.397319"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6317455768585205,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:31.038248"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6333198547363281,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:31.679798"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5947742462158203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:32.282572"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6793138980865479,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:32.978887"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4357798099517822,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:33.434706"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3981752395629883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:33.847630"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4196312427520752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:35.282969"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6744599342346191,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:35.972104"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5719089508056641,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:36.558509"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4596874713897705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:37.028943"
    }
  ],
  "sus-uta7/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8695604801177979,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:37.928189"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4673292636871338,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:38.410607"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42801403999328613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:38.854825"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43952155113220215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:39.311132"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5248465538024902,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:39.846728"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8346343040466309,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:40.696526"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6060893535614014,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:41.317161"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5126380920410156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:41.844147"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.0753684043884277,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:43.933449"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0686841011047363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:45.011633"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49348926544189453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:45.514114"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6416840553283691,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:46.173794"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6968765258789062,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:46.887639"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.938347816467285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:49.841955"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2536659240722656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:51.105262"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.8509306907653809,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:52.965780"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5049662590026855,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:53.485763"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.785447359085083,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:54.288369"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.066405773162842,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:56.374816"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46726107597351074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:56.855312"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5049240589141846,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:38:57.377208"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 4.051279544830322,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:39:01.445399"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.010617971420288,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:39:02.472394"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "data_at_end",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4068310260772705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_data_at_end_20250723_092821\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": true
      },
      "timestamp": "2025-07-23T09:39:02.932206"
    }
  ]
}