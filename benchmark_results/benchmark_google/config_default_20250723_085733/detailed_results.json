{
  "healthcare-dataset/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9457621574401855,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:34.260860"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.662773609161377,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:34.942935"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7050478458404541,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:35.665002"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5309107303619385,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:36.208558"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5299100875854492,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:36.753478"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44658470153808594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:37.213510"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38791346549987793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:37.619205"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3906080722808838,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:38.019788"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38951587677001953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:38.415296"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4075150489807129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:38.837116"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34125661849975586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:39.191386"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3946976661682129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:39.601252"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "a",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4361724853515625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:40.052862"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0450060367584229,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:41.113702"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "a",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5361745357513428,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:41.666722"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "a",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37587451934814453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:42.047700"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "a",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39578914642333984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:42.449489"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3832404613494873,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:42.844728"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.397625207901001,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:43.260456"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4438440799713135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:43.719696"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3636815547943115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:44.094369"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42990779876708984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:44.539053"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4511382579803467,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:45.003594"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7098004817962646,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:45.726397"
    }
  ],
  "healthcare-dataset/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5005526542663574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:46.247430"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5028154850006104,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:46.790317"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49744248390197754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:47.307762"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.51019287109375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:47.835643"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.452225923538208,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:48.305881"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5042364597320557,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:48.823161"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4717545509338379,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:49.310338"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47776007652282715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:49.802112"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5318770408630371,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:50.350202"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4626450538635254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:50.829672"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4428825378417969,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:51.288722"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5452675819396973,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:51.872048"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8191826343536377,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:52.783235"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4344913959503174,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:53.224883"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3690192699432373,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:53.610871"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn, mIchElLe daniELs",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44695067405700684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:54.074814"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3771214485168457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:54.469420"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4139254093170166,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:54.899348"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4886760711669922,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:55.406868"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6254417896270752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:56.045688"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3946566581726074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:56.458841"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4506969451904297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:56.927535"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7480838298797607,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:57.690915"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4697914123535156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:58.177095"
    }
  ],
  "healthcare-dataset/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5655989646911621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:58.768865"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0558152198791504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:57:59.837667"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3649280071258545,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:00.214223"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38661885261535645,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:00.609037"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3632802963256836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:00.985315"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4207422733306885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:01.421048"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3699331283569336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:01.803002"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6061716079711914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:02.419948"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.380687952041626,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:02.815833"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4129753112792969,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:03.240882"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3649723529815674,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:03.616181"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39107465744018555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:04.024897"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4192485809326172,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:04.459271"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3875157833099365,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:04.850783"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42702150344848633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:05.295143"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38976120948791504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:05.700574"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45755982398986816,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:06.168120"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43405890464782715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:06.615999"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4676644802093506,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:07.094791"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44297146797180176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:07.553821"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6110293865203857,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:08.178764"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4672553539276123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:08.663340"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.277327537536621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:09.955651"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.539578914642334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:10.511335"
    }
  ],
  "healthcare-dataset/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41766858100891113,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:10.957172"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7339980602264404,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:12.036149"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4199836254119873,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:12.557164"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5466339588165283,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:13.122751"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38857340812683105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:13.525783"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5931684970855713,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:14.137238"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "116",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4024806022644043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:14.552717"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4071624279022217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:15.970420"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "116",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35941624641418457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:16.344826"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "116",
      "llm_response": "There are no respondents with Gender Female and Blood Type O+.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4462251663208008,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:16.802830"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5176815986633301,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:17.337532"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "116",
      "llm_response": "There are no respondents with Gender Female and Blood Type O+.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4977436065673828,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:17.851741"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "There are no respondents with Blood Type O+ and Test Results Normal.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46515393257141113,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:18.329069"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "No respondent numbers match the criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48832058906555176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:18.830579"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "There are no respondents with Blood Type O+ and Test Results Normal.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8875529766082764,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:19.733353"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37577319145202637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:20.124108"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.341724157333374,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:20.477470"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "No respondent numbers meet this criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49120283126831055,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:20.979673"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "43",
      "llm_response": "33",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4227137565612793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:21.407347"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35715413093566895,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:21.782523"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39108848571777344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:22.189146"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "43",
      "llm_response": "No respondent numbers meet both criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.426516056060791,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:22.629226"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35646820068359375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:22.997686"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4144930839538574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:23.429647"
    }
  ],
  "healthcare-dataset/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5329227447509766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:23.976535"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4490773677825928,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:24.442134"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4273655414581299,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:24.880961"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.514310359954834,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:25.414077"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37833619117736816,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:25.809229"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6780524253845215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:26.503893"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4408836364746094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:26.962672"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4894273281097412,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:27.462836"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.393399715423584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:27.871919"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4110584259033203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:28.295969"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4139707088470459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:28.726381"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43058085441589355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:29.171198"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4713306427001953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:29.660950"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43019819259643555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:30.102750"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4249746799468994,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:30.532691"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44676852226257324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:30.992127"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37545275688171387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:31.372601"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43898606300354004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:31.826440"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41362786293029785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:32.245053"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4328267574310303,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:32.691714"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47214365005493164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:33.180560"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4734041690826416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:33.670752"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4012296199798584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:34.089181"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4316112995147705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:34.531282"
    }
  ],
  "healthcare-dataset/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "2, 4, 5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44001317024230957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:34.991050"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4304187297821045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:35.437076"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4901893138885498,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:35.942599"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4394490718841553,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:36.400035"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4368772506713867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:36.851917"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7423231601715088,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:37.605727"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "1, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6214118003845215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:38.234729"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117, 57, 102",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4414241313934326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:38.692233"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5248465538024902,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:39.232746"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117, 102",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43877124786376953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:39.677522"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37642836570739746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:40.060543"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117, 102",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48804736137390137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:40.559606"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "1, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.190772294998169,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:41.768659"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38203930854797363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:42.170901"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4037821292877197,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:42.588914"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39832305908203125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:42.996266"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.566992998123169,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:43.629250"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5359535217285156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:44.236194"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42603373527526855,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:44.671247"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45482563972473145,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:45.143260"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41435790061950684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:45.564921"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4629800319671631,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:46.044969"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4457433223724365,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:46.506343"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4254603385925293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:46.948796"
    }
  ],
  "isbar/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46590161323547363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:47.442706"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41733622550964355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:47.871723"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.375856876373291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:48.272888"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4224586486816406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:48.705629"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3928043842315674,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:49.147409"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41773414611816406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:49.579539"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.621884822845459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:50.213582"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38815903663635254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:50.615617"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3945941925048828,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:51.022189"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43985438346862793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:51.480020"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3810405731201172,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:51.879045"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4098966121673584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:52.303943"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5224711894989014,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:52.838349"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4368155002593994,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:53.282166"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4789135456085205,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:53.767462"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6984331607818604,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:54.483104"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3927185535430908,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:54.893041"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5131280422210693,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:55.420868"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4004025459289551,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:55.837643"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3735208511352539,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:56.227167"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3451240062713623,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:56.583552"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36786580085754395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:56.969709"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5145077705383301,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:57.490222"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4067361354827881,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:57.911567"
    }
  ],
  "isbar/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48150086402893066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:58.410693"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3867619037628174,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:58.802453"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34284234046936035,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:59.160913"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46292710304260254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:58:59.643486"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4112815856933594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:00.073214"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3910071849822998,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:00.479161"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "16",
      "llm_response": "11, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4407021999359131,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:00.938446"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37897825241088867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:01.329650"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "16",
      "llm_response": "11, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3852384090423584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:01.731878"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "16",
      "llm_response": "11, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46056127548217773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:02.207448"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "16",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3819441795349121,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:02.610134"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "16",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4765791893005371,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:03.099343"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40432286262512207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:03.518361"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3883976936340332,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:03.921765"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5788891315460205,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:04.511929"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4630906581878662,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:04.989964"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4358398914337158,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:05.442799"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3789806365966797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:05.838063"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37543725967407227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:06.227655"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3786170482635498,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:06.622531"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4714188575744629,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:07.108727"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40137743949890137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:07.525044"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33056092262268066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:07.867621"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46842288970947266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:08.351683"
    }
  ],
  "isbar/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4588027000427246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:08.837783"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.407625675201416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:09.261413"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6904194355010986,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:09.969794"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3940005302429199,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:10.378796"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40909886360168457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:10.802730"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39946436882019043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:11.214870"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36890244483947754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:11.596322"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3752884864807129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:12.000578"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37885499000549316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:12.393573"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4287691116333008,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:12.838150"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9448821544647217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:13.800729"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.7652409076690674,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:15.583140"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4628596305847168,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:16.066613"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5001688003540039,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:16.589574"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4167358875274658,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:17.019174"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36809825897216797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:17.399483"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4070565700531006,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:17.822020"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5907273292541504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:18.420776"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38861775398254395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:18.823770"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3983337879180908,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:19.242658"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38277721405029297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:19.630416"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38275957107543945,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:20.018176"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38278985023498535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:20.413328"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37173891067504883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:20.806499"
    }
  ],
  "isbar/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41464781761169434,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:21.244652"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9178299903869629,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:22.170672"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35996007919311523,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:22.545997"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3725886344909668,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:22.933689"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3546767234802246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:23.295351"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36672282218933105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:23.680351"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42571377754211426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:24.122131"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3785130977630615,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:24.513235"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3427243232727051,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:24.872488"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4, 6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3941991329193115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:25.282391"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "9",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3767392635345459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:25.671852"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1548802852630615,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:26.842756"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43926548957824707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:27.289989"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4122040271759033,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:27.709194"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49735355377197266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:28.227630"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.6376054286956787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:29.879163"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.910120964050293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:30.802972"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3828589916229248,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:31.200860"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19, 11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42290639877319336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:31.636454"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4052739143371582,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:32.046683"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37209630012512207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:32.425758"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19, 11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4584176540374756,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:32.914180"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19, 11, 6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4381401538848877,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:33.369046"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6826403141021729,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:34.062522"
    }
  ],
  "isbar/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47982144355773926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:34.565677"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5430266857147217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:35.125999"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44432878494262695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:35.586926"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5032494068145752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:36.108343"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6005275249481201,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:36.724088"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5351877212524414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:37.266078"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 10,
      "llm_response": "12",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40135765075683594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:37.684972"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37151551246643066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:38.073064"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 10,
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8951225280761719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:38.975182"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6703834533691406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:39.658212"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2692062854766846,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:40.938607"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 10,
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5096971988677979,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:41.462281"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3737967014312744,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:41.852050"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.366008996963501,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:42.235682"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39443302154541016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:42.642814"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38172125816345215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:43.040046"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32064270973205566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:43.371679"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3727738857269287,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:43.761423"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3524484634399414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:44.130381"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35634899139404297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:44.491680"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36677980422973633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:44.865502"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.4168035984039307,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:47.297957"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.527712345123291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:47.839163"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3484222888946533,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:48.203861"
    }
  ],
  "isbar/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49253034591674805,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:48.955406"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8028233051300049,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:49.774561"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40598082542419434,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:50.198529"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42287254333496094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:50.636623"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36501407623291016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:51.018408"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.084059715270996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:52.115444"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8119168281555176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:52.947426"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7073686122894287,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:53.671804"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8243367671966553,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:54.510454"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5730700492858887,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:55.100698"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5659375190734863,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:55.682911"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0761594772338867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:56.769105"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8774447441101074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:57.664916"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40660691261291504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:58.084521"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7188360691070557,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:58.866418"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9232335090637207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T08:59:59.831650"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6289381980895996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:00.477900"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44057655334472656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:00.928466"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4564197063446045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:01.400880"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5129795074462891,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:01.934546"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4041557312011719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:02.354682"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39768457412719727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:02.767649"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 8, 3, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42565155029296875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:03.212661"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4991235733032227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\isbar\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:04.727821"
    }
  ],
  "self-reported-mental-health-college-students-2022/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5492620468139648,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:05.315924"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5349018573760986,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:05.865213"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5374629497528076,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:06.421460"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5742521286010742,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:07.003672"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5966272354125977,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:07.615656"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.673729658126831,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:08.309404"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5726466178894043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:08.897878"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5142478942871094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:09.426630"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5258779525756836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:09.969122"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5486249923706055,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:10.532197"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5819680690765381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:11.129172"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5545508861541748,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:11.700725"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5709033012390137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:12.283339"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4305260181427002,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:12.726011"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5384442806243896,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:13.282253"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5608582496643066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:13.856752"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5679159164428711,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:14.441281"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5878877639770508,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:15.037117"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5704925060272217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:15.622280"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7060451507568359,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:16.344334"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5983157157897949,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:16.961551"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.567507266998291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:17.546928"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5348014831542969,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:18.094805"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5600366592407227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:18.670118"
    }
  ],
  "self-reported-mental-health-college-students-2022/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5479166507720947,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:19.243493"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8607814311981201,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:20.114422"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5275371074676514,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:20.650311"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5443553924560547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:21.212668"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5597400665283203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:21.789060"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.741809606552124,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:22.552206"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5747888088226318,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:23.142700"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44328904151916504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:23.601663"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5376195907592773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:24.157433"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5437705516815186,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:24.718875"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5874133110046387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:25.323782"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6919271945953369,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:26.032727"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8781321048736572,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:26.928109"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7466115951538086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:27.691766"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 27",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5498008728027344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:28.257974"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5985012054443359,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:28.871681"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5858263969421387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:29.475495"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8257718086242676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:30.316822"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8589086532592773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:31.191326"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18, 4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5340518951416016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:31.741309"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5670027732849121,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:32.322771"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18, 134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.611569881439209,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:32.949321"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18, 134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6582515239715576,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:33.621292"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5521953105926514,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:34.191330"
    }
  ],
  "self-reported-mental-health-college-students-2022/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5223379135131836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:34.739324"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46503663063049316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:35.219608"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5581824779510498,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:35.796024"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6172254085540771,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:36.434617"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5455803871154785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:36.997505"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4603147506713867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:37.476088"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6091761589050293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:38.101255"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4476349353790283,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:38.565866"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5827572345733643,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:39.163885"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6385235786437988,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:39.823590"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5805411338806152,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:40.421052"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48450303077697754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:40.920522"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4528522491455078,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:41.392387"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4489023685455322,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:41.858976"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5529325008392334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:42.419085"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6295819282531738,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:43.066486"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5469677448272705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:43.629123"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6979138851165771,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:44.344016"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4462594985961914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:44.806545"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4619405269622803,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:45.282275"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5884301662445068,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:45.889279"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5812013149261475,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:46.490077"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5459880828857422,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:47.052638"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.467728853225708,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:47.532154"
    }
  ],
  "self-reported-mental-health-college-students-2022/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1002886295318604,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:48.653205"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46814584732055664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:49.145356"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5215537548065186,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:49.685178"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5897262096405029,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:50.295902"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5696544647216797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:50.878824"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5572648048400879,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:51.448530"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0153687000274658,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:52.482910"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45874643325805664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:52.956427"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5899291038513184,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:53.565678"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6021037101745605,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:54.184471"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8392179012298584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:55.039661"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6333775520324707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:55.687045"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2145469188690186,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:56.921782"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4492309093475342,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:57.407483"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5308685302734375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:57.950314"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5846917629241943,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:58.546004"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6978299617767334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:59.259811"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5670759677886963,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:00:59.840092"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1019518375396729,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:00.949028"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "There is no respondent with a Socio-economic status score of 5 and a Life satisfaction score of 10 in the provided data.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6853713989257812,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:01.650188"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4984157085418701,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:02.165754"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5582342147827148,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:02.740878"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5384974479675293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:03.290683"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5458719730377197,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:03.843556"
    }
  ],
  "self-reported-mental-health-college-students-2022/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6455581188201904,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:04.504093"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4257380962371826,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:04.941806"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49662065505981445,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:05.455725"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7260541915893555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:06.193762"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6721951961517334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:06.874626"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6130173206329346,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:07.497661"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5936956405639648,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:08.108836"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5424416065216064,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:08.699328"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5580339431762695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:09.268382"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5520079135894775,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:09.830671"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5383126735687256,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:10.378979"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5246891975402832,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:10.921082"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6363742351531982,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:11.574756"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5069830417633057,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:12.101165"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6254129409790039,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:12.747557"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5690486431121826,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:13.330760"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6813642978668213,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:14.024098"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5981988906860352,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:14.750033"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5895519256591797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:15.351783"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5548875331878662,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:15.926658"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6021718978881836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:16.545167"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6185276508331299,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:17.177669"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5735335350036621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:17.766812"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6399950981140137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:18.418100"
    }
  ],
  "self-reported-mental-health-college-students-2022/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4307863712310791,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:18.873268"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5762729644775391,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:19.462514"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.555593729019165,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:20.031494"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.678478479385376,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:20.726978"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5751173496246338,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:21.324232"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "There is no response data provided.  Therefore, no respondent numbers can be identified.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5915138721466064,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:21.927910"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3871943950653076,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:22.330365"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.509880781173706,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:22.857625"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5699505805969238,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:23.436253"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6488325595855713,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:24.100892"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5914711952209473,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:24.705339"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "None",
      "llm_response": "There is no data in the provided responses section.  Therefore, no respondent numbers can be identified.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6138839721679688,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:25.337055"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4548685550689697,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:25.871918"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5453495979309082,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:26.433256"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7425689697265625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:27.192015"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8116927146911621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:28.018947"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5536942481994629,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:28.593617"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "There is no data in the provided responses section.  Therefore, no respondent numbers can be identified.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5886898040771484,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:29.198545"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "66",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4785444736480713,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:29.692357"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "110, 45, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5424633026123047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:30.241922"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "110, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6974608898162842,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:30.951225"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 110, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7345261573791504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:31.698792"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "110, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6315107345581055,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:32.344256"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "There is no data in the provided responses section.  Therefore, it is impossible to answer the question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6808826923370361,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:33.039856"
    }
  ],
  "stack-overflow-2022-developer-survey/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42662787437438965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:33.497837"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46328020095825195,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:33.976283"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4907219409942627,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:34.484538"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.533116340637207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:35.054361"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5359117984771729,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:35.607317"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45705389976501465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:36.082087"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47562098503112793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:36.564457"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41709017753601074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:36.990568"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.483553409576416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:37.490485"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49210095405578613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:37.997904"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42165493965148926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:38.433966"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45933985710144043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:38.907930"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4521164894104004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:39.415340"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3920259475708008,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:39.822904"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7006077766418457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:40.538709"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4434053897857666,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:40.997114"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43657565116882324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:41.449548"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43934130668640137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:41.893890"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3974916934967041,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:42.303583"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40973401069641113,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:42.719292"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5402317047119141,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:43.275508"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.493755578994751,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:43.781262"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3678748607635498,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:44.164405"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38637781143188477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:44.561791"
    }
  ],
  "stack-overflow-2022-developer-survey/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43565797805786133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:45.024598"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4823570251464844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:45.523943"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4636726379394531,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:46.004027"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4516582489013672,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:46.468691"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4917161464691162,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:46.983013"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49201202392578125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:47.525496"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5112042427062988,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:48.053060"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6111860275268555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:48.681918"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49820375442504883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:49.351140"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4670424461364746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:49.831322"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4383106231689453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:50.280863"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.598792314529419,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:50.892917"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4824037551879883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:51.392289"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4754323959350586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:51.885338"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49340009689331055,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:52.396237"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4693741798400879,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:52.879847"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48614025115966797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:53.372958"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5453929901123047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:53.939304"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5333003997802734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:54.488629"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5455451011657715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:55.079949"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47937703132629395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:55.567307"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4708826541900635,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:56.047171"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49456238746643066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:56.554737"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4671511650085449,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:57.029363"
    }
  ],
  "stack-overflow-2022-developer-survey/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4795033931732178,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:57.524730"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7860751152038574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:58.324524"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5685679912567139,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:58.904082"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43642377853393555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:59.359193"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42290759086608887,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:01:59.797362"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47159457206726074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:00.281851"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7163252830505371,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:01.013397"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39971923828125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:01.427270"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4541778564453125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:01.892700"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44933485984802246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:02.357891"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40801477432250977,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:02.782218"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.430591344833374,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:03.227815"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5999283790588379,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:03.843757"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40775322914123535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:04.268295"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5054395198822021,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:04.781882"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4375741481781006,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:05.232148"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3776986598968506,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:05.626796"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43839359283447266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:06.081971"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5221884250640869,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:06.624474"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43611931800842285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:07.074296"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5143697261810303,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:07.600568"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5876851081848145,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:08.205584"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44161200523376465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:08.659186"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45839905738830566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:09.135139"
    }
  ],
  "stack-overflow-2022-developer-survey/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4173572063446045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:09.573955"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40497660636901855,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:09.997579"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4066190719604492,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:10.419599"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42180895805358887,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:10.859083"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3922426700592041,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:11.268328"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41358137130737305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:11.700279"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4138658046722412,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:12.134748"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4250154495239258,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:12.575754"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3991727828979492,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:12.991061"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4369230270385742,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:13.441119"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4156663417816162,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:13.880797"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41101527214050293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:14.309791"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45660829544067383,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:14.782711"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5042068958282471,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:15.301915"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4377107620239258,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:15.760077"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4278249740600586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:16.205895"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "272",
      "llm_response": "There are no respondents in the provided data that meet both criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5285129547119141,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:16.753633"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4901003837585449,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:17.259921"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48110294342041016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:17.752511"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4905672073364258,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:18.267078"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39003562927246094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:18.673789"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8292121887207031,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:19.518527"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43025803565979004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:19.969176"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3834264278411865,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:20.365117"
    }
  ],
  "stack-overflow-2022-developer-survey/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5969185829162598,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:20.984017"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4145848751068115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:21.418286"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3955543041229248,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:21.822820"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5334761142730713,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:22.372212"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3997495174407959,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:22.790171"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4027087688446045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:23.212420"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4147055149078369,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:23.642808"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41315436363220215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:24.062987"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4672679901123047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:24.540203"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.428142786026001,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:24.983130"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39370179176330566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:25.389685"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5887765884399414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:25.996494"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48445677757263184,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:26.496767"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5112817287445068,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:27.025057"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3899514675140381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:27.429477"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43825817108154297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:27.882565"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36643362045288086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:28.269062"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3970470428466797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:28.677552"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48917722702026367,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:29.182297"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8684682846069336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:30.066377"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4127235412597656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:30.491156"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6238753795623779,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:31.129412"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39544034004211426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:31.540426"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44799089431762695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:32.003001"
    }
  ],
  "stack-overflow-2022-developer-survey/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48773193359375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:32.517510"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5276694297790527,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:33.059726"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3219594955444336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:34.398704"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5687167644500732,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:34.987063"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.506854772567749,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:35.508845"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5563445091247559,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:36.079916"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 72583, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1763641834259033,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:37.270830"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.515195369720459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:37.800976"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 423, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5541591644287109,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:38.372110"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7006161212921143,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:39.091242"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 72583, 423, 186, 202, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6827309131622314,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:39.792012"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 72583, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8281283378601074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:40.638558"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45677924156188965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:41.115691"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47732019424438477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:41.615879"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5549120903015137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:42.253793"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5399596691131592,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:42.809690"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6098113059997559,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:43.434937"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48573970794677734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:43.934829"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "29105, 72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5531375408172607,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:44.504624"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4599418640136719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:44.980762"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "29105, 72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5050840377807617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:45.504853"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40694189071655273,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:45.928014"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "29105, 72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4671952724456787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:46.406622"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4423511028289795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:46.864353"
    }
  ],
  "sus-uta7/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4196438789367676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:47.310485"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4137134552001953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:47.736406"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3832230567932129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:48.137721"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36661624908447266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:48.517948"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3320276737213135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:48.868222"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3842346668243408,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:49.408414"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38177490234375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:49.796190"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5749719142913818,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:50.385878"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3405160903930664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:50.746175"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6370184421539307,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:51.398796"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5272610187530518,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:51.942048"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48995351791381836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:52.447929"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3740818500518799,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:52.837337"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39304637908935547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:53.246389"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3423633575439453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:53.596801"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5299975872039795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:54.142645"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5921828746795654,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:55.752824"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.334920883178711,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:57.101287"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5679624080657959,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:57.677224"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38162899017333984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:58.073930"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4006218910217285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:58.490350"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37374210357666016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:58.879091"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3277256488800049,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:59.222269"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.363128662109375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:02:59.604615"
    }
  ],
  "sus-uta7/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4730043411254883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:00.095860"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46605682373046875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:00.572918"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40673160552978516,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:00.995370"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42819833755493164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:01.441987"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3893101215362549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:01.848719"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4493989944458008,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:02.316520"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4099466800689697,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:02.732653"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39664316177368164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:03.144046"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3976743221282959,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:03.554954"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38271546363830566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:03.956640"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.349773645401001,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:04.323736"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5026535987854004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:04.842829"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41323328018188477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:05.273514"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39624667167663574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:05.684775"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38431477546691895,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:06.087456"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5050625801086426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:06.608593"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38701558113098145,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:07.010636"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49905848503112793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:07.524921"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45830655097961426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:07.997319"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43564438819885254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:08.448904"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38297200202941895,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:08.844198"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4522674083709717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:09.314206"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44375085830688477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:09.774781"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5706155300140381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:10.359745"
    }
  ],
  "sus-uta7/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37162089347839355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:10.754953"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3929784297943115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:11.153920"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4152343273162842,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:11.587296"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3887927532196045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:11.986540"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3528275489807129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:12.357562"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3793909549713135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:12.754102"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37967419624328613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:13.149616"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40944385528564453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:13.575506"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4023582935333252,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:13.983025"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0676934719085693,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:15.204725"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38257813453674316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:15.602289"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3911755084991455,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:16.000701"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5096781253814697,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:16.521347"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4082005023956299,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:16.949069"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36363649368286133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:17.320875"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3862118721008301,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:17.716060"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39985156059265137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:18.122059"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37038612365722656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:18.504435"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41086673736572266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:18.927014"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35266590118408203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:19.287937"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3389108180999756,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:19.642862"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37445712089538574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:20.033036"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3326687812805176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:20.381157"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3744051456451416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:20.774970"
    }
  ],
  "sus-uta7/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3972177505493164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:21.192244"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4151265621185303,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:21.622448"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.386218786239624,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:22.024469"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3949575424194336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:22.434755"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3852853775024414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:22.836790"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.432725191116333,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:23.281475"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4135708808898926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:23.711852"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "There are no respondents with Group A and Frequent_Usage of 5.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4926605224609375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:24.221293"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3472747802734375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:24.588019"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "There are no respondents with Group A and Frequent_Usage of 5 in the provided data.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5211360454559326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:25.115583"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34917259216308594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:25.477526"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5144264698028564,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:26.004378"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.66322922706604,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:26.685593"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4267458915710449,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:27.129021"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49211907386779785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:27.638804"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40186381340026855,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:28.053322"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4602792263031006,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:28.519716"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4419550895690918,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:28.978363"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36641812324523926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:29.358264"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "Answer:",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39238834381103516,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:29.767395"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4207587242126465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:30.204327"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "Answer:",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48826146125793457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:30.705355"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "No respondent numbers meet this criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45067358016967773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:31.170669"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "No respondent numbers meet this criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45670485496520996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:31.642574"
    }
  ],
  "sus-uta7/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5238955020904541,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:32.191350"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4694652557373047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:32.676384"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42801690101623535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:33.122404"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4017934799194336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:33.541821"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38178157806396484,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:33.940957"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3861215114593506,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:34.343482"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36063599586486816,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:34.722076"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4079742431640625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:35.142040"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3877906799316406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:35.545656"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3663947582244873,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:35.926960"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3558998107910156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:36.295976"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37997889518737793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:36.691962"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39842820167541504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:37.107771"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3970961570739746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:37.524487"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38251709938049316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:37.921975"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36423754692077637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:38.296202"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38907337188720703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:38.697259"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4395871162414551,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:39.150535"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44316816329956055,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:39.604692"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45347094535827637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:40.074434"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4416542053222656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:40.532680"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7035322189331055,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:41.246950"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4722926616668701,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:41.733228"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.59757399559021,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:42.344446"
    }
  ],
  "sus-uta7/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4361536502838135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:42.810263"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43854260444641113,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:43.255780"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4213080406188965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:43.682062"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4311981201171875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:44.118253"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7523293495178223,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:44.886416"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43511390686035156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:45.344239"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40517401695251465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:45.767405"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3939778804779053,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:46.177668"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5064926147460938,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:46.698984"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42035818099975586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:47.129329"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43488574028015137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:47.581748"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4198317527770996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:48.018909"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4604470729827881,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:48.497364"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5516359806060791,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:49.068352"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3719062805175781,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:49.588374"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46981024742126465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:50.067265"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37180662155151367,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:50.455097"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4165945053100586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:50.887730"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "default",
      "question": "",
      "expected_answer": "48",
      "llm_response": "55, 48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43833446502685547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:51.342679"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "default",
      "question": "",
      "expected_answer": "48",
      "llm_response": "55, 48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5080997943878174,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:51.864993"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "default",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48, 55, 62",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4257969856262207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:52.302773"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "default",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48, 40",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4573051929473877,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:52.778033"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "default",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48, 55",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.566392183303833,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:53.358628"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "default",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48, 40, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6627066135406494,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_default_20250723_085733\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:54.025796"
    }
  ]
}