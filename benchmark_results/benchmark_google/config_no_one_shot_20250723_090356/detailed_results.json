{
  "healthcare-dataset/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48497748374938965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:56.566054"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.387509822845459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:56.968987"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3569355010986328,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:57.337237"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40463757514953613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:57.755056"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5793914794921875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:58.349448"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4272778034210205,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:58.791744"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4111509323120117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:59.218860"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3235893249511719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:59.557630"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3749663829803467,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:03:59.943765"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36821985244750977,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:00.323985"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3528151512145996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:00.690429"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37198901176452637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:01.073670"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34316134452819824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:01.427696"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4063253402709961,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:01.850005"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41463422775268555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:02.276117"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3332993984222412,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:02.615008"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3447842597961426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:02.974808"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4204137325286865,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:03.405917"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1552445888519287,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:04.573656"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5127847194671631,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:05.100444"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.375338077545166,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:05.483997"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39379334449768066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:05.892530"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3647501468658447,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:06.268023"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42299818992614746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:06.802429"
    }
  ],
  "healthcare-dataset/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.472980260848999,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:07.297395"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42171669006347656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:07.731873"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4442164897918701,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:08.192077"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "Respondent94, Respondent87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4024195671081543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:08.608798"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42807960510253906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:09.052102"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "94",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3470947742462158,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:09.413958"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4058828353881836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:09.829605"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4079430103302002,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:10.251587"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4511110782623291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:10.711635"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4426298141479492,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:11.164259"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4149754047393799,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:11.595209"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4180338382720947,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:12.023246"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "Respondent 145",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47040224075317383,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:12.504599"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "145",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34032416343688965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:12.860064"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36019086837768555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:13.233419"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "No one",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32050466537475586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:13.566726"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "No one",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3423426151275635,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:13.920358"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3158290386199951,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:14.247758"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3635880947113037,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:14.622082"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3820059299468994,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:15.018789"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43631482124328613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:15.469333"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3485119342803955,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:15.831876"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3906595706939697,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:16.234767"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4555237293243408,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:16.696272"
    }
  ],
  "healthcare-dataset/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3976130485534668,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:17.103855"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44184207916259766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:17.552695"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3552408218383789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:17.921253"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32305192947387695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:18.275153"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3205745220184326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:18.601379"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3931567668914795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:19.009807"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.406574010848999,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:19.427608"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36313748359680176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:19.802835"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.338381290435791,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:20.153978"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3590250015258789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:20.516991"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35187864303588867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:20.883171"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32750773429870605,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:21.221722"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3941342830657959,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:21.632293"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33779382705688477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:21.983073"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3645784854888916,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:22.363678"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46822285652160645,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:22.844857"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33664512634277344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:23.191495"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4495382308959961,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:23.657280"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42244458198547363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:24.094682"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36412715911865234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:24.473807"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3523979187011719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:24.837025"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44045329093933105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:25.290304"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3362739086151123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:25.640374"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37319278717041016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:26.025262"
    }
  ],
  "healthcare-dataset/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3512904644012451,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:26.400590"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8210361003875732,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:27.233009"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36433887481689453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:27.612627"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3235914707183838,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:27.950530"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.348752498626709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:28.317261"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3787727355957031,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:28.706963"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3924579620361328,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:29.112673"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38028407096862793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:29.503946"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36785221099853516,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:29.884871"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8510823249816895,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:30.746931"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35152292251586914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:31.110778"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6056399345397949,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:31.726396"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41371774673461914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:32.151486"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3965270519256592,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:32.553012"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.8503413200378418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:34.413856"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6212270259857178,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:35.050067"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49350452423095703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:35.558814"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6224122047424316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:36.279003"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.370250940322876,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:36.656241"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42464685440063477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:37.094124"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5033516883850098,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:37.614024"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3393673896789551,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:37.962930"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3385179042816162,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:38.316452"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4259674549102783,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:38.754048"
    }
  ],
  "healthcare-dataset/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42172813415527344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:39.194929"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4038262367248535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:39.612066"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3815011978149414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:40.005272"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3811063766479492,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:40.399959"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33584070205688477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:40.747801"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4657554626464844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:41.226115"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.394848108291626,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:41.635966"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3510129451751709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:41.996991"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3298497200012207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:42.337500"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3756422996520996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:42.727366"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36000728607177734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:43.101533"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4367821216583252,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:43.552729"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8185770511627197,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:44.384324"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6770741939544678,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:45.073374"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4142186641693115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:45.504557"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4093945026397705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:45.927655"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3446824550628662,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:46.281750"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3778715133666992,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:46.675640"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39016175270080566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:47.081168"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.330974817276001,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:47.422137"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36753177642822266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:47.802911"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4038057327270508,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:48.220363"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5645170211791992,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:48.795879"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4060661792755127,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:49.213903"
    }
  ],
  "healthcare-dataset/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "2, 4, 5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40462398529052734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:49.818038"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38443779945373535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:50.213466"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "39, 90, 94",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4050736427307129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:50.623522"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5143482685089111,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:51.149576"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "39, 90, 94",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43663787841796875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:51.601477"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4315524101257324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:52.045236"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34781599044799805,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:52.406659"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3603806495666504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:52.775666"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.372927188873291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:53.163928"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44372987747192383,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:53.622657"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0798332691192627,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:54.715886"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36604785919189453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:55.085931"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34693145751953125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:55.441988"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3757510185241699,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:55.831948"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5005676746368408,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:56.346521"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39923644065856934,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:56.754564"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3450191020965576,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:57.109606"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5547761917114258,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:57.670382"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "3, 5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44075608253479004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:58.121360"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38742947578430176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:58.518373"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47069835662841797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:59.004157"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4024670124053955,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:59.417628"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41584038734436035,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:04:59.837465"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6009509563446045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:00.514419"
    }
  ],
  "isbar/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3807356357574463,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:00.921130"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37262701988220215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:01.309426"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45815181732177734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:01.783232"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3872199058532715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:02.185184"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3999154567718506,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:02.600763"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42684459686279297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:03.045205"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4111595153808594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:03.470382"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4818446636199951,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:03.962623"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34578514099121094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:04.323181"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34157633781433105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:04.677744"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4026496410369873,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:05.095292"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35512804985046387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:05.461421"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41254353523254395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:05.885771"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42700791358947754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:06.323760"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39725494384765625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:06.733771"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49095678329467773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:07.239462"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4512655735015869,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:07.705144"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4617729187011719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:08.170880"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4051990509033203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:08.585289"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43283724784851074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:09.031437"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5189456939697266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:09.560858"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3882486820220947,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:09.955054"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9270944595336914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:10.892936"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7506875991821289,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:11.657120"
    }
  ],
  "isbar/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "18",
      "llm_response": "Respondent 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39783620834350586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:12.079347"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37437009811401367,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:12.467261"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "18",
      "llm_response": "Respondent 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.628713846206665,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:13.109833"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "18",
      "llm_response": "Respondent18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3369739055633545,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:13.461838"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "18",
      "llm_response": "Respondent 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36478161811828613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:13.837885"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39691615104675293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:14.248550"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3709840774536133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:14.629536"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3631412982940674,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:15.004334"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4009532928466797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:15.418038"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "16",
      "llm_response": "Respondent16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3524589538574219,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:15.784293"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38635683059692383,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:16.218608"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "16",
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5047290325164795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:16.741497"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3630683422088623,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:17.117567"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5003020763397217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:17.627888"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42957425117492676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:18.067677"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "15",
      "llm_response": "Respondent15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3436851501464844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:18.420989"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3253512382507324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:18.760367"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3743617534637451,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:19.150116"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5384163856506348,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:19.702974"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4121260643005371,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:20.122073"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6136336326599121,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:20.745180"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "Respondent3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35404253005981445,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:21.112602"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36437439918518066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:21.489932"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3379368782043457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:21.843543"
    }
  ],
  "isbar/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36267805099487305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:22.226681"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39438462257385254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:22.628073"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3540360927581787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:22.998368"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3483879566192627,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:23.363791"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.336627721786499,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:23.712246"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41506528854370117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:24.137276"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.405423641204834,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:24.552704"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.373790979385376,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:24.935478"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3416879177093506,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:25.282620"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39400410652160645,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:25.691874"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37430238723754883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:26.080626"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38111209869384766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:26.475997"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33626294136047363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:26.823282"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3883175849914551,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:27.225296"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34276747703552246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:27.579348"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38299083709716797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:27.973657"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4097616672515869,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:28.388427"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34742212295532227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:28.745871"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32692480087280273,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:29.086294"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3795948028564453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:29.478396"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4708375930786133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:29.962489"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3470499515533447,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:30.323069"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44422078132629395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:30.782218"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33560967445373535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:31.130823"
    }
  ],
  "isbar/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3793201446533203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:31.538567"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3404395580291748,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:31.890039"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.373476505279541,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:32.272645"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39150166511535645,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:32.712101"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3472762107849121,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:33.075361"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33858704566955566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:33.421112"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "9",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3937406539916992,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:33.824548"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "9",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.341569185256958,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:34.179926"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34522223472595215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:34.539174"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "9",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3548862934112549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:34.906041"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "9",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36810994148254395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:35.289044"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4, 9",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3813173770904541,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:35.684388"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3428771495819092,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:36.038836"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3461110591888428,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:36.399949"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34808969497680664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:36.761293"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7764945030212402,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:37.552109"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3432044982910156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:37.906993"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3389871120452881,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:38.260968"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19, 11, 6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43004894256591797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:38.705026"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19, 11, 6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3797616958618164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:39.094465"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "6, 11, 19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45075392723083496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:39.559223"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19,11,6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4253520965576172,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:40.001745"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19, 11, 6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4032773971557617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:40.419176"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19,11,6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38019871711730957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:40.802378"
    }
  ],
  "isbar/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39078760147094727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:41.219929"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6147446632385254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:41.840660"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3544344902038574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:42.205089"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3361551761627197,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:42.559555"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39476585388183594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:42.970456"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33721137046813965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:43.318895"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 10,
      "llm_response": "12",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41689372062683105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:43.744462"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4375476837158203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:44.198016"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 10,
      "llm_response": "16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36204051971435547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:44.571032"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 10,
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36805081367492676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:44.955958"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34278297424316406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:45.309801"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 10,
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37452054023742676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:45.698276"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35048437118530273,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:46.056770"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3375248908996582,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:46.400305"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3339691162109375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:46.747289"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34142184257507324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:47.104716"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0002930164337158,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:48.108989"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3541407585144043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:48.476132"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37840747833251953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:48.867910"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3606545925140381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:49.233552"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3650941848754883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:49.613652"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4244694709777832,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:50.230151"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5480971336364746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:50.788709"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3471052646636963,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:51.148489"
    }
  ],
  "isbar/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "3, 8, 19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39122796058654785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:51.559373"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3755979537963867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:51.948382"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41896533966064453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:52.383067"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4416007995605469,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:52.838661"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "3, 8, 19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37360215187072754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:53.226259"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38106536865234375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:53.622867"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5521793365478516,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:54.185053"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6,14,7,9,20,15,8,17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4831669330596924,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:54.683196"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5472474098205566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:55.247402"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5149106979370117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:55.768519"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5758905410766602,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:56.358605"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5347902774810791,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:56.908403"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3996853828430176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:57.324099"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3681826591491699,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:57.699255"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3791987895965576,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:58.094463"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "Respondent2,Respondent4,Respondent1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38216447830200195,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:58.490630"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3776681423187256,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:58.879286"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39305996894836426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:59.287756"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38586902618408203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:05:59.689658"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4569857120513916,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:00.156980"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3597886562347412,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:00.531771"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6404705047607422,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:01.183966"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38019514083862305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:01.573710"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39298486709594727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\isbar\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:01.976635"
    }
  ],
  "self-reported-mental-health-college-students-2022/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4844942092895508,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:02.481426"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4285149574279785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.8,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.8,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:02.920612"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43253135681152344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:03.367284"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4344804286956787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:03.806758"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.430309534072876,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:04.248892"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4511899948120117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:04.712750"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4384288787841797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:05.162802"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38289856910705566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:05.552655"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41690731048583984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:05.983534"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4308815002441406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:06.428452"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4337501525878906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:06.872208"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4519534111022949,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:07.337989"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47010207176208496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:07.823288"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3918442726135254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:08.228873"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.447451114654541,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:08.685304"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48903322219848633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:09.184339"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43738675117492676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:09.636279"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46131014823913574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:10.108319"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4320085048675537,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:10.552420"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37894511222839355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:10.941029"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4784073829650879,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:11.434446"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5729718208312988,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:12.055408"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4899251461029053,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:12.567351"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4324052333831787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:13.010787"
    }
  ],
  "self-reported-mental-health-college-students-2022/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.687666654586792,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:13.721043"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4147653579711914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:14.153400"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0995028018951416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:15.261071"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "101",
      "llm_response": "Respondent101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49329638481140137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:15.769347"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "101",
      "llm_response": "Respondent 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4720168113708496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:16.255565"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48819875717163086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:16.754293"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48235464096069336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:17.260564"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5581982135772705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:17.845437"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6032993793487549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:18.598369"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "148",
      "llm_response": "Respondent148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5115253925323486,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:19.171378"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.512455940246582,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:19.709842"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42500758171081543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:20.144017"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4923818111419678,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:20.642396"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3821265697479248,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:21.038192"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5105373859405518,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:21.559944"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "Respondent46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4474453926086426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:22.017518"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45957398414611816,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:22.487647"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44246506690979004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:22.943347"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18, 4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4560811519622803,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:23.413701"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40598416328430176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:23.830467"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18, 4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44625139236450195,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:24.288132"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "Respondent18,Respondent4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4563891887664795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:24.754940"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18, 134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49161410331726074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:25.261382"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4593336582183838,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:25.724679"
    }
  ],
  "self-reported-mental-health-college-students-2022/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3640415668487549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:26.109075"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6613435745239258,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:26.775405"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4144890308380127,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:27.205374"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5354235172271729,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:27.754818"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4358029365539551,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:28.205793"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4254746437072754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:28.636823"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4315774440765381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:29.078877"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6572294235229492,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:29.747124"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42814111709594727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:30.190493"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4456157684326172,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:30.651771"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4380612373352051,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:31.103271"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4356083869934082,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:31.555484"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4192981719970703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:31.991063"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39276719093322754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:32.399048"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41356658935546875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:32.824086"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48085975646972656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:33.315910"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46941709518432617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:33.795510"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40939903259277344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:34.210904"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4159862995147705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:34.639197"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3865623474121094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:35.038759"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4413120746612549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:35.490836"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45935773849487305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:35.962176"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4594302177429199,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:36.434548"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4192783832550049,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:36.865448"
    }
  ],
  "self-reported-mental-health-college-students-2022/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9116101264953613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:37.790050"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4646737575531006,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:38.292703"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.456939697265625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:38.767651"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4586005210876465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:39.244350"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46831750869750977,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:39.726157"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43260669708251953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:40.173349"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6884973049163818,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:40.877027"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1635758876800537,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:42.052593"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48641514778137207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:42.553538"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4623713493347168,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:43.023305"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46129679679870605,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:43.497573"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4863123893737793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:43.998036"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6998615264892578,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:44.733870"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3677639961242676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:45.115655"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41418004035949707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:45.540430"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5193405151367188,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:46.065761"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4248659610748291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:46.496621"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44744253158569336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:46.955609"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6451919078826904,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:47.616411"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3592872619628906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:47.989529"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4192080497741699,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:48.421743"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4735374450683594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:48.906614"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49733996391296387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:49.418834"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8102283477783203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:50.240049"
    }
  ],
  "self-reported-mental-health-college-students-2022/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4435081481933594,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:50.698953"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3890070915222168,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:51.101984"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4652080535888672,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:51.580476"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5696382522583008,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:52.161112"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4412357807159424,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:52.614880"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42255711555480957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:53.052310"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5248115062713623,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:53.591856"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38454532623291016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:53.980401"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4261484146118164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:54.421547"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45102667808532715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:54.886742"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43613696098327637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:55.337584"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4246969223022461,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:55.774733"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44284725189208984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:56.232661"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43738508224487305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:56.683666"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4253847599029541,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:57.123059"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4589822292327881,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:57.595349"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5023119449615479,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:58.120671"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4800882339477539,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:58.617176"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45955801010131836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:59.094938"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.504523515701294,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:06:59.614759"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.439655065536499,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:00.064382"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5972981452941895,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:00.673068"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4280688762664795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:01.109382"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49514079093933105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:01.608557"
    }
  ],
  "self-reported-mental-health-college-students-2022/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3631281852722168,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:01.989743"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39839839935302734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:02.403162"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48904919624328613,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:02.907487"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48142290115356445,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:03.403929"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.521543025970459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:03.941805"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "There is no responses section provided.  Therefore, I cannot answer the question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5181300640106201,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:04.475178"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3684356212615967,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:04.858421"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3821089267730713,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:05.253791"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43736863136291504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:05.705150"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5174233913421631,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:06.233177"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42933106422424316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:06.677501"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "None",
      "llm_response": "No respondent numbers are provided in the given data.  Therefore, no answer can be given.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5126233100891113,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:07.205245"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3816647529602051,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:07.601484"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4045133590698242,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:08.018219"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4866645336151123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:08.517224"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "Respondent124, Respondent20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49172306060791016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:09.022149"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4697449207305908,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:09.495864"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "There is no responses section provided.  Therefore, I cannot answer the question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5162601470947266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:10.025347"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "66",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7011170387268066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:10.740482"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 131, 110, 66, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5482633113861084,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:11.302257"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 131, 110, 66, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6183450222015381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:11.935382"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "131,110,137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6659975051879883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:12.614815"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 131, 110, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5532522201538086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:13.186078"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "There is no responses section provided.  Therefore, I cannot answer the question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5291147232055664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:13.727861"
    }
  ],
  "stack-overflow-2022-developer-survey/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4566173553466797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:14.198472"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38209009170532227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:14.593591"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5036160945892334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:15.113250"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3577241897583008,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:15.482769"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.915682315826416,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:16.414097"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5472517013549805,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:17.060336"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4421539306640625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:17.518105"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4163386821746826,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:17.948479"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9350905418395996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:18.907403"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37522196769714355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:19.297662"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3963592052459717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:19.711010"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45329737663269043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:20.227330"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4284543991088867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:20.673132"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37413859367370605,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:21.053255"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41808056831359863,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:21.481369"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36436939239501953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:21.859440"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36011743545532227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:22.233858"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3938748836517334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:22.639757"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.31798291206359863,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:22.960738"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3330075740814209,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:23.309521"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3885467052459717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:23.713073"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33170437812805176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:24.059401"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32988786697387695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:24.399904"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33585309982299805,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:24.746765"
    }
  ],
  "stack-overflow-2022-developer-survey/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6837127208709717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:25.454468"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40512681007385254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:25.872576"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.420623779296875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:26.302913"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7338414192199707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:27.051754"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.392075777053833,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:27.456239"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738,72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4316556453704834,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:27.898773"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3841993808746338,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:28.297190"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41004323959350586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:28.721236"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5068140029907227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:30.233038"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49176692962646484,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:30.747954"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42229127883911133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:31.184422"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.471987247467041,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:31.692384"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.244532585144043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:32.953918"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382,29109,123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5456297397613525,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:33.511544"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4349994659423828,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:33.960758"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382,29109,123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44638943672180176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:34.420062"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5307111740112305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:34.961074"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43851161003112793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:35.413998"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49619507789611816,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:35.920899"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46408748626708984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:36.400681"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42555761337280273,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:36.837964"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740,73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4573242664337158,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:37.309653"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4980332851409912,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:37.839944"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4157991409301758,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:38.267744"
    }
  ],
  "stack-overflow-2022-developer-survey/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3535783290863037,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:38.643131"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38285303115844727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:39.032980"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37839460372924805,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:39.425588"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37465810775756836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:39.814389"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3628249168395996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:40.184404"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3601861000061035,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:40.559307"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3394279479980469,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:40.913720"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3540337085723877,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:41.282881"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3117949962615967,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:41.608672"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6424555778503418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:42.262647"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40632200241088867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:42.677702"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34900879859924316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:43.037625"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3888223171234131,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:43.439626"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36336660385131836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:43.816319"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3178243637084961,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:44.142808"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.31656956672668457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:44.470187"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3317737579345703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:44.815983"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34861063957214355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:45.181251"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4081282615661621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:45.601346"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.393887996673584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:46.011401"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40108418464660645,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:46.427794"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4199824333190918,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:46.858960"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3603780269622803,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:47.228613"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3813762664794922,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:47.622720"
    }
  ],
  "stack-overflow-2022-developer-survey/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3421154022216797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:47.989833"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3607163429260254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:48.366573"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3394746780395508,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:48.718923"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1968708038330078,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:49.927788"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.505181074142456,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:50.447933"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39987826347351074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:50.865369"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7844433784484863,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:51.662949"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4111952781677246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:52.086121"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35674452781677246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:52.462723"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3674356937408447,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:52.842385"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4318544864654541,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:53.283827"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4933485984802246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:53.820644"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "272",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32601380348205566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:54.160383"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "272",
      "llm_response": "No respondents meet this criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3951551914215088,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:54.560495"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "272",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3328745365142822,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:54.907366"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "272",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38324975967407227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:55.302611"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "272",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33139729499816895,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:55.650004"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "272",
      "llm_response": "No respondents meet this criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42923688888549805,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:56.093256"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4640653133392334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:56.566279"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36184215545654297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:56.940993"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39019155502319336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:57.343918"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34963560104370117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:57.708559"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35231876373291016,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:58.073614"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41614627838134766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:58.503611"
    }
  ],
  "stack-overflow-2022-developer-survey/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3640146255493164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:58.892066"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38299560546875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:59.288847"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4845707416534424,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:07:59.789684"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.365922212600708,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:00.170604"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36414098739624023,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:00.545947"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4343900680541992,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:00.991538"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5273997783660889,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:01.531567"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3852057456970215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:01.928244"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3835303783416748,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:02.322341"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38214921951293945,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:02.711624"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3924856185913086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:03.114681"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3712496757507324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:03.496915"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39107298851013184,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:03.899357"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34072446823120117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:04.253101"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.404205322265625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:04.670289"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32982397079467773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:05.011593"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3610677719116211,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:05.385990"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.357175350189209,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:05.758168"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4032597541809082,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:06.173843"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3796873092651367,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:06.565851"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3928685188293457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:06.969303"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4162611961364746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:07.399060"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.352492094039917,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:07.761947"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37727832794189453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:08.149619"
    }
  ],
  "stack-overflow-2022-developer-survey/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5263538360595703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:08.699432"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47428250312805176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:09.191694"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43544769287109375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:09.636456"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4440946578979492,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:10.094140"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5001013278961182,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:10.609059"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46053290367126465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:11.081303"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710,423,186,359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49077486991882324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:11.587248"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710,423,186,359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5210254192352295,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:12.121786"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710,423,186,359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5305032730102539,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:12.666148"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "423,72710,186,359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5118069648742676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:13.190571"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710,423,186,359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7328472137451172,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:13.933789"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710,423,186",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5252807140350342,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:14.474093"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45603513717651367,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:14.941367"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3921635150909424,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:15.344122"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3771345615386963,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:15.730882"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4487740993499756,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:16.191270"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.363506555557251,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:16.566178"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72969",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38172197341918945,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:16.962282"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4142172336578369,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:17.388157"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48577308654785156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:17.891885"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3822505474090576,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:18.289130"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37421369552612305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:18.678271"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34888744354248047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:19.038151"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4228034019470215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:19.476596"
    }
  ],
  "sus-uta7/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47176337242126465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:19.975288"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37430667877197266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:20.365878"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38130831718444824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:20.761849"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36233949661254883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:21.129186"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36532139778137207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:21.511522"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5652265548706055,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:22.087691"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33261656761169434,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:22.429933"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3227686882019043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:22.767719"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3997461795806885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:23.197865"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44975829124450684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:23.656803"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.606147289276123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:24.274983"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3722100257873535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:24.656614"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3985941410064697,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:25.066456"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.31803202629089355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:25.399646"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3283267021179199,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:25.741991"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4217493534088135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:26.177009"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6009633541107178,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:26.792501"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34633636474609375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:27.149855"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3988606929779053,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:27.560732"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34441542625427246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:27.918961"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37978434562683105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:28.309765"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3709559440612793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:28.691759"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32784557342529297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:29.031921"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.364454984664917,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:29.405651"
    }
  ],
  "sus-uta7/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38767457008361816,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:29.816741"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3939380645751953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:30.226021"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3948836326599121,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:30.635753"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43703460693359375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:31.087007"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39402008056640625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:31.495035"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "10, 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3720285892486572,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:31.879469"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4499397277832031,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:32.343435"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3750777244567871,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:32.731993"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34149718284606934,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:33.086351"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3540160655975342,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:33.455318"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3529698848724365,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:33.823187"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36954617500305176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:34.205738"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36014246940612793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:34.579715"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4147353172302246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:35.003446"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4042487144470215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:35.415700"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36107897758483887,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:35.789638"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3695859909057617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:36.171851"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5086486339569092,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:36.685498"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41503262519836426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:37.115087"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40108394622802734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:37.524881"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4316396713256836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:37.968481"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49091196060180664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:38.467448"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42535400390625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:38.907664"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41135478019714355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:39.323033"
    }
  ],
  "sus-uta7/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39030885696411133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:39.732594"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.31195783615112305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:40.059358"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32427000999450684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:40.399846"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36119627952575684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:40.775568"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3292829990386963,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:41.110896"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3429381847381592,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:41.468820"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32896852493286133,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:41.810272"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3262186050415039,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:42.151006"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3267974853515625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:42.491809"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3223423957824707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:42.829050"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33858752250671387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:43.176922"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38929128646850586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:43.580962"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3171193599700928,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:43.907076"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3831801414489746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:44.302280"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34472227096557617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:44.656775"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33095359802246094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:44.997915"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.335801362991333,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:45.351305"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.345827579498291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:45.713605"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3858945369720459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:46.112162"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3573300838470459,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:46.482682"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4121685028076172,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:46.907498"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3162806034088135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:47.233781"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32684326171875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:47.569624"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3370039463043213,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:47.919612"
    }
  ],
  "sus-uta7/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40872883796691895,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:48.352870"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4117143154144287,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:48.774599"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5593550205230713,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:49.350647"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "Respondent11,Respondent85,Respondent90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4219934940338135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:49.782938"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3921492099761963,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:50.189331"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4232025146484375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:50.726526"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3900566101074219,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:51.122562"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3254842758178711,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:51.461041"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3374760150909424,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:51.809278"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3161048889160156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:52.136839"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32872533798217773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:52.470131"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3776822090148926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:52.858814"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4334981441497803,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:53.303318"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42017054557800293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:53.738792"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39721012115478516,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:54.150438"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3581414222717285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:54.523119"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3695392608642578,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:54.903545"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38887858390808105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:55.309310"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9654111862182617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:56.288484"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3141319751739502,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:56.615848"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32995104789733887,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:56.961563"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3274848461151123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:57.299145"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3524506092071533,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:57.662895"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35901546478271484,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:58.031558"
    }
  ],
  "sus-uta7/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33307576179504395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:58.386821"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3453090190887451,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:58.747156"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35709142684936523,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:59.120506"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3447606563568115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:59.517656"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3395707607269287,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:08:59.872023"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.330913782119751,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:00.218674"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3226127624511719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:00.551767"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3355093002319336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:00.899142"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32545900344848633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:01.240586"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6461589336395264,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:01.892719"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3963613510131836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:02.302414"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35408449172973633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:02.671202"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3328211307525635,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:03.018341"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3226191997528076,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:03.358329"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32732176780700684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:03.691040"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34807705879211426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:04.052331"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.31937694549560547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:04.386948"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34610748291015625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:04.746967"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37123990058898926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:05.128728"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3317716121673584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:05.475781"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5707669258117676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:07.059471"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.4880423545837402,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:09.558014"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33193540573120117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:09.899445"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44024205207824707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:10.350137"
    }
  ],
  "sus-uta7/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41965150833129883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:10.790250"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40282702445983887,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:11.198075"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.422482967376709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:11.635833"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3570241928100586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:12.003848"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3642139434814453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:12.379927"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45473623275756836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:12.849684"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40697216987609863,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:13.270920"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49,77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3543510437011719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:13.636283"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3734900951385498,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:14.025187"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49,77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3590991497039795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:14.399413"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3624000549316406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:14.774811"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4220118522644043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:15.212325"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3744351863861084,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:15.600090"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3653101921081543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:15.976410"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3594841957092285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:16.350912"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3680601119995117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:16.733370"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4279978275299072,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:17.174264"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.360210657119751,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:17.538752"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4511141777038574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:17.998882"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36281752586364746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:18.371727"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37442970275878906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:18.758156"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.338909387588501,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:19.108047"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3568861484527588,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:19.477626"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_one_shot",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36566758155822754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_one_shot_20250723_090356\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": false,
        "include_partition": true,
        "include_role": true,
        "include_format": true,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:09:19.858263"
    }
  ]
}