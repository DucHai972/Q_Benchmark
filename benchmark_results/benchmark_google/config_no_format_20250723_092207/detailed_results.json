{
  "healthcare-dataset/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4881319999694824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:07.855255"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44046664237976074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:08.299845"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36214756965637207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:08.666995"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5200848579406738,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:09.192941"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5305426120758057,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:09.728048"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the billing amount for mRS. jamiE cAMPBELl?",
      "expected_answer": "17440",
      "llm_response": "17440",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3770415782928467,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:10.110070"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5125155448913574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:10.627580"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3958139419555664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:11.027673"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41205430030822754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:11.444954"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41145753860473633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:11.860500"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38497495651245117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:12.249475"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the insurance provider of JessE BaNks?",
      "expected_answer": "Aetna",
      "llm_response": "Aetna",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37595653533935547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:12.629431"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "Abnormal",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36357593536376953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:12.998991"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3721919059753418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:13.375185"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "a",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.377274751663208,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:13.757455"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "a",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38086676597595215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:14.143293"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "a",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3560471534729004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:14.504371"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What are the test results of JAMEs Ross?",
      "expected_answer": "Abnormal",
      "llm_response": "a",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3902149200439453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:14.899782"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43474769592285156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:15.337530"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3758518695831299,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:15.717382"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3719639778137207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:16.093507"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4616358280181885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:16.560163"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.342670202255249,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:16.906847"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the billing amount for DAVid higgInS?",
      "expected_answer": "24948",
      "llm_response": "24948",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40065717697143555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:17.311521"
    }
  ],
  "healthcare-dataset/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4490504264831543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:17.768573"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4622478485107422,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:18.235822"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4264030456542969,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:18.667215"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44418954849243164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:19.116649"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44988250732421875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:19.570630"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_response": "mIcHAeL MaRTIn, kayLa padillA",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4314742088317871,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:20.007076"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45064210891723633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:20.460882"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4626657962799072,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:20.927560"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3990976810455322,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:21.331904"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4352760314941406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:21.771141"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7760086059570312,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:22.551041"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "RENEE bAilEY, dWAYnE DAViS",
      "llm_response": "RENEE bAilEY, dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4819924831390381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:23.038061"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42148280143737793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:23.463792"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5556974411010742,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:24.024888"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37653326988220215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:24.405407"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn, mIchElLe daniELs",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47313690185546875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:24.883932"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn, mIchElLe daniELs",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42885851860046387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:25.316737"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "ShAUN GuzmAn",
      "llm_response": "ShAUN GuzmAn",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40250468254089355,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:25.724235"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4218728542327881,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:26.149108"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39277052879333496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:26.546878"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4232940673828125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:26.975171"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4235568046569824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:27.402729"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3634326457977295,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:27.770099"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "dWAYnE DAViS",
      "llm_response": "dWAYnE DAViS",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4093296527862549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:28.183437"
    }
  ],
  "healthcare-dataset/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2067840099334717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:29.399422"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37179088592529297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:29.774473"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41428470611572266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:30.193752"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35822391510009766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:30.555981"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43074631690979004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:30.993732"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3882012367248535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:31.386957"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40590476989746094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:31.798220"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6570568084716797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:32.462133"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3863646984100342,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:32.852533"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6398332118988037,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:33.496214"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41897058486938477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:33.919385"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40857481956481934,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:34.333502"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45870113372802734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:34.796992"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3757667541503906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:35.176981"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.707775354385376,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:35.889522"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.498680591583252,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:37.392213"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.393937349319458,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:37.790151"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3923957347869873,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:38.188555"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.439373254776001,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:38.631963"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3945307731628418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:39.031498"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36505746841430664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:39.401028"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.377636194229126,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:39.782995"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3622593879699707,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:40.150059"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4544501304626465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:40.609206"
    }
  ],
  "healthcare-dataset/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38036322593688965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:40.997274"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35231733322143555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:41.354785"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4044606685638428,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:41.763483"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3522837162017822,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:42.120465"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3245100975036621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:42.450654"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "63",
      "llm_response": "63",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3763000965118408,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:42.831953"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "116",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38048267364501953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:43.218194"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36963343620300293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:43.593785"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "116",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36959147453308105,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:43.968177"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "116",
      "llm_response": "There are no respondents with Gender Female and Blood Type O+.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5223870277404785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:44.495760"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "116",
      "llm_response": "116",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34138989448547363,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:44.842763"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "116",
      "llm_response": "No respondent numbers meet this criteria.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4400608539581299,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:45.286414"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34223151206970215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:45.633995"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "There are no respondents with Blood Type O+ and Test Results Normal.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5430159568786621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:46.182023"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38748931884765625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:46.573510"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36519384384155273,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:46.943556"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "47",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1661713123321533,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:48.114859"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "There are no respondents with Blood Type O+ and Test Results Normal.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44517040252685547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:48.563030"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34831690788269043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:48.917611"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36348772048950195,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:49.285500"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3267338275909424,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:49.617381"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6346867084503174,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:50.256071"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5261125564575195,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:50.787296"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "43",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5787172317504883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:51.370312"
    }
  ],
  "healthcare-dataset/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42823171615600586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:51.811547"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5063276290893555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:52.321876"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3645591735839844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:52.690431"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0865211486816406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:53.780953"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.445878267288208,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:54.232830"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4664154052734375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:54.704267"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4652407169342041,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:55.173510"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5325379371643066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:55.712044"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41741299629211426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:56.133467"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4279360771179199,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:56.567534"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3493618965148926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:56.921107"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5442409515380859,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:57.469790"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5521116256713867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:58.027007"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4524707794189453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:58.484482"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.372969388961792,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:58.862114"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44001007080078125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:59.305445"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3792431354522705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:22:59.689863"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "10",
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4193880558013916,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:00.113230"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42977142333984375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:00.548203"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41115236282348633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:00.964059"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3493537902832031,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:01.317554"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4587535858154297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:01.780222"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41637110710144043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:02.200787"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.398345947265625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:02.602891"
    }
  ],
  "healthcare-dataset/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "2, 4, 5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5001602172851562,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:03.110229"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4716758728027344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:03.585894"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41289663314819336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:04.004416"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4231381416320801,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:04.431535"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45404982566833496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:04.890587"
    },
    {
      "case_id": "case_1",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 39, 90",
      "llm_response": "94, 39, 90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4299473762512207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:05.325342"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6868336200714111,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:06.017171"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117, 57",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40729236602783203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:06.428454"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5153276920318604,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:06.947794"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117, 102",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.421720027923584,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:07.374583"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4277975559234619,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:07.806387"
    },
    {
      "case_id": "case_2",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "105, 31, 58",
      "llm_response": "117, 102",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42624855041503906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:08.236877"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "1, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4804389476776123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:08.722324"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4285609722137451,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:09.155974"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45099592208862305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:09.611316"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41027259826660156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:10.027589"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4869568347930908,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:10.517546"
    },
    {
      "case_id": "case_3",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "68, 131, 66",
      "llm_response": "73, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3977699279785156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:10.919319"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5102930068969727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:11.435047"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44914913177490234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:11.887195"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4115326404571533,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:12.304700"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39974451065063477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:12.708443"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44361424446105957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:13.156060"
    },
    {
      "case_id": "case_4",
      "dataset": "healthcare-dataset",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "94, 131",
      "llm_response": "49, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4676787853240967,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\healthcare-dataset\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:13.627986"
    }
  ],
  "isbar/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40763092041015625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:14.041972"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4123218059539795,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:14.458253"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4202587604522705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:14.883492"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41368889808654785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:15.301209"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1322622299194336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:16.437693"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the session name for respondent 21?",
      "expected_answer": "II (Anaphylaxsis)",
      "llm_response": "II (Anaphylaxsis)",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41671156883239746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:16.859204"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5094437599182129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:17.372637"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3558952808380127,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:17.733530"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3399016857147217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:18.078578"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36971068382263184,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:18.453421"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3295290470123291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:18.786946"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the identification score for respondent 17?",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3645296096801758,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:19.155850"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5711495876312256,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:19.733151"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4102959632873535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:20.148426"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3903651237487793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:20.543798"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5245685577392578,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:21.072364"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4515993595123291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:21.528925"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the date for respondent 13?",
      "expected_answer": "2025-05-02",
      "llm_response": "2025-05-02",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5357651710510254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:22.068844"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.387298583984375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:22.461147"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3624286651611328,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:22.827904"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3243370056152344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:23.157419"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40742969512939453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:23.570284"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34963393211364746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:23.924887"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the global rating score for respondent 17?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4232902526855469,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:24.352174"
    }
  ],
  "isbar/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37583255767822266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:24.734006"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.629296064376831,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:25.368831"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33832740783691406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:25.712919"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38300156593322754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:26.099920"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35271143913269043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:26.457604"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "18",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36196470260620117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:26.825569"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "16",
      "llm_response": "11, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4405229091644287,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:27.284745"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "16",
      "llm_response": "18, 16",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4051215648651123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:27.695004"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "16",
      "llm_response": "11, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3765532970428467,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:28.075053"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "16",
      "llm_response": "11, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4160947799682617,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:28.495148"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "16",
      "llm_response": "18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33606672286987305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:28.835216"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "16",
      "llm_response": "11, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42650389671325684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:29.267011"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36347532272338867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:29.633484"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45214033126831055,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:30.090623"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6996991634368896,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:30.794324"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38327932357788086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:31.181599"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.374774694442749,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:31.559935"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "15",
      "llm_response": "15",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39051270484924316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:31.954419"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41779136657714844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:32.377322"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5112719535827637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:33.893788"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35134410858154297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:34.250279"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3607335090637207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:34.616026"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3549680709838867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:34.975731"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6824207305908203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:35.662268"
    }
  ],
  "isbar/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36478567123413086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:36.034197"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38379693031311035,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:36.423078"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38373732566833496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:36.812814"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36055779457092285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:37.177372"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36310887336730957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:37.544680"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3720877170562744,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:37.921798"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.370347261428833,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:38.295787"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37476682662963867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:38.677559"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40067505836486816,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:39.082851"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3712582588195801,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:39.458115"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35296058654785156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:39.816075"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36321496963500977,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:40.184291"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39515066146850586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:40.584440"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3824450969696045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:40.973206"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42973947525024414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:41.406943"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3562462329864502,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:41.768060"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4975123405456543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:42.269514"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 3,
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4021632671356201,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:42.677614"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4013817310333252,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:43.083960"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3621327877044678,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:43.451037"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47399210929870605,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:43.930012"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3660247325897217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:44.299052"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45614147186279297,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:44.759657"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3916444778442383,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:45.158200"
    }
  ],
  "isbar/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.376758337020874,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:45.544192"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37273430824279785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:45.921131"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3561129570007324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:46.281057"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3875575065612793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:46.673627"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35631608963012695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:47.034950"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "14",
      "llm_response": "14",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40743160247802734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:47.447525"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5707106590270996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:48.022926"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5163509845733643,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:48.545170"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3529677391052246,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:48.904232"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4, 6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3804659843444824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:49.288698"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "9",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7998061180114746,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:50.093274"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "21, 23",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4186520576477051,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:50.517155"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41672658920288086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:50.939556"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4232766628265381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:51.366831"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35626840591430664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:51.727377"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4072554111480713,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:52.139626"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40018391609191895,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:52.547783"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49745702743530273,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:53.049240"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19, 11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4426257610321045,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:53.524538"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4415595531463623,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:53.970975"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3831183910369873,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:54.358044"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19, 11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3988196849822998,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:54.761225"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34132862091064453,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:55.108168"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 16",
      "llm_response": "19",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43817782402038574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:55.551215"
    }
  ],
  "isbar/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4522705078125,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:56.011586"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35974693298339844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:56.376601"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3638911247253418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:56.745840"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5554194450378418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:57.306262"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4450953006744385,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:57.755825"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40491580963134766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:58.165921"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 10,
      "llm_response": "12",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38004422187805176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:58.550082"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38298797607421875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:58.937683"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 10,
      "llm_response": "13",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3967306613922119,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:59.338757"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4273233413696289,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:23:59.771082"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 10,
      "llm_response": "10",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3692436218261719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:00.145644"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 10,
      "llm_response": "11",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38132500648498535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:00.531202"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4235379695892334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:00.959591"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35883593559265137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:01.322426"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3492884635925293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:01.676722"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4195404052734375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:02.102451"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33061695098876953,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:02.439064"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37773799896240234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:02.820907"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38752222061157227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:03.213429"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3549060821533203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:03.574000"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39537668228149414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:03.974613"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3524792194366455,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:04.332094"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3925020694732666,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:04.731532"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3413851261138916,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:05.077917"
    }
  ],
  "isbar/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41162824630737305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:05.497524"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5004441738128662,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:06.001968"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40967655181884766,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:06.417651"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4271881580352783,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:06.850079"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.374377965927124,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:07.228843"
    },
    {
      "case_id": "case_1",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19, 8, 3",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4088132381439209,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:07.643121"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5605309009552002,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:08.207650"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5440080165863037,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:08.755794"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.532966136932373,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:09.293826"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5300493240356445,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:09.829277"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47658801078796387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:10.309883"
    },
    {
      "case_id": "case_2",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_response": "6, 14, 7, 9, 20, 15, 8, 17",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5309271812438965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:10.845781"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46289491653442383,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:11.313634"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4102747440338135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:11.729016"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5180418491363525,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:12.252059"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39908766746520996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:12.656985"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4546196460723877,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:13.116091"
    },
    {
      "case_id": "case_3",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2, 4, 1",
      "llm_response": "2, 4, 1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.407855749130249,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:13.529749"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4184226989746094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:13.952189"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 8, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4203207492828369,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:14.376930"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 8, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4010043144226074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:14.783410"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 8, 3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42617011070251465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:15.215464"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 8, 3, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6340937614440918,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:15.853557"
    },
    {
      "case_id": "case_4",
      "dataset": "isbar",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "19",
      "llm_response": "19, 22",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4473302364349365,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\isbar\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:16.304887"
    }
  ],
  "self-reported-mental-health-college-students-2022/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5721778869628906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:16.885555"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4260835647583008,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:17.318905"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5226790904998779,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:17.845584"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5779974460601807,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:18.429672"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5814130306243896,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:19.015892"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "For respondent 129, what is the value for 'Appetite Changes' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5450489521026611,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:19.565493"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5720822811126709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:20.143018"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1755456924438477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:21.323544"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5393490791320801,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:21.866892"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5614120960235596,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:22.433165"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5629775524139404,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:23.001251"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the life satisfaction for respondent 148?",
      "expected_answer": "2.0",
      "llm_response": "2.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5892608165740967,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:23.594506"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5678448677062988,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:24.168595"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43538784980773926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:24.609305"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5646679401397705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:25.179296"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5385382175445557,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:25.723462"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5345969200134277,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:26.262057"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "For respondent 99, what is the value for 'Irritability' in the 'Anxiety Symptoms Frequency' category?",
      "expected_answer": "1.0",
      "llm_response": "1.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5561912059783936,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:26.823098"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5595667362213135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:27.387665"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42633676528930664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:27.819176"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5616285800933838,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:28.385079"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5869877338409424,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:28.976567"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5483222007751465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:29.528891"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "For respondent 81, what is the value for 'Suicidal Thoughts' in the 'Depressive Symptoms Frequency' category?",
      "expected_answer": "0.0",
      "llm_response": "0.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6278941631317139,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:30.162278"
    }
  ],
  "self-reported-mental-health-college-students-2022/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5580184459686279,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:30.728344"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44586920738220215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:31.179206"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6165144443511963,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:31.801497"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5607051849365234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:32.367828"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.519965648651123,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:32.893131"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "101",
      "llm_response": "101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.626823902130127,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:33.524956"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.611391544342041,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:34.140987"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5170369148254395,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:34.661882"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5330615043640137,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:35.199945"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5566458702087402,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:35.760590"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6199636459350586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:36.384741"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "148",
      "llm_response": "148",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5434525012969971,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:36.932740"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8434836864471436,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:37.782321"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.564415454864502,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:38.350737"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 27",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2670745849609375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:39.623809"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6037259101867676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:40.232892"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5678277015686035,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:40.804718"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "46",
      "llm_response": "46, 101",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7652056217193604,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:41.574764"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9178094863891602,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:42.497579"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "18, 4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5753803253173828,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:43.078090"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5592410564422607,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:43.642527"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18, 134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7808189392089844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:44.428207"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18, 134",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6051256656646729,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:45.038464"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4, 18, 134",
      "llm_response": "4, 18",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5873401165008545,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:45.630770"
    }
  ],
  "self-reported-mental-health-college-students-2022/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4821205139160156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:46.121898"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44432592391967773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:46.571486"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6649298667907715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:47.240836"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.575559139251709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:47.822022"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5244381427764893,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:48.350461"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7537994384765625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:49.108506"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45149922370910645,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:49.566006"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43631553649902344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:50.005322"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5428249835968018,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:50.551149"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6023526191711426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:51.157501"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.009624719619751,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:52.172235"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4489872455596924,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:52.626214"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46459126472473145,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:53.097802"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1283526420593262,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:54.229299"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5837874412536621,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:54.817118"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6185879707336426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:55.444085"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9180212020874023,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:56.370069"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.523829460144043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:56.903145"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48949575424194336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:57.400915"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.448211669921875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:57.858114"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7607073783874512,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:58.623289"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6035497188568115,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:59.231602"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5150980949401855,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:24:59.750219"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6151034832000732,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:00.368638"
    }
  ],
  "self-reported-mental-health-college-students-2022/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0819900035858154,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:01.460335"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42159104347229004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:01.886889"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.559138298034668,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:02.451028"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6140413284301758,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:03.070805"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5143430233001709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:03.589871"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5533368587493896,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:04.149214"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29",
      "llm_response": "82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0672485828399658,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:05.221452"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8491675853729248,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:06.075467"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.2509160041809082,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:07.333204"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29",
      "llm_response": "82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5652730464935303,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:07.904386"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5902965068817139,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:08.500724"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29",
      "llm_response": "34, 82",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6051654815673828,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:09.111447"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0592458248138428,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:10.175701"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43577122688293457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:10.617192"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5566215515136719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:11.178799"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5503537654876709,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:11.733399"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.524590253829956,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:12.264307"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "25, 124",
      "llm_response": "87",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6587686538696289,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:12.929171"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1103763580322266,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:14.043578"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "There is no respondent with a Socio-economic status score of 5 and a Life satisfaction score of 10 in the provided data.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.714951753616333,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:14.765706"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5073442459106445,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:15.277143"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0857114791870117,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:16.365955"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "There is no respondent with a Socio-economic status score of 5 and a Life satisfaction score of 10 in the provided data.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7455787658691406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:17.116629"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5714380741119385,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:17.693439"
    }
  ],
  "self-reported-mental-health-college-students-2022/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6155478954315186,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:18.319281"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44687461853027344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:18.774406"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5325191020965576,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:19.313087"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7260918617248535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:20.044177"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6188957691192627,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:20.667981"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7325313091278076,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:21.409151"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6008768081665039,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:22.017556"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4138457775115967,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:22.439390"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5369315147399902,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:22.982229"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5383601188659668,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:23.525652"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5893278121948242,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:24.121228"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5069327354431152,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:24.635176"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5394108295440674,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:25.182207"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48926234245300293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:25.677773"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5764100551605225,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:26.257382"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5644793510437012,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:26.827516"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.583815336227417,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:27.416252"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5694072246551514,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:27.990890"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1231069564819336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:29.119762"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.538336992263794,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:29.662060"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8364179134368896,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:30.503890"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5385010242462158,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:31.046971"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7044916152954102,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:31.757314"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "6",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5689272880554199,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:32.334125"
    }
  ],
  "self-reported-mental-health-college-students-2022/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3639795780181885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:32.705272"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4966413974761963,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:33.209756"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5731396675109863,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:33.788894"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.615081787109375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:34.408988"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "53, 97",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5728178024291992,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:34.988805"
    },
    {
      "case_id": "case_1",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "53, 97",
      "llm_response": "There is no data provided in the `<responses>` section, therefore it is impossible to answer the question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.589277982711792,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:35.586217"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3631739616394043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:35.956048"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48829174041748047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:36.448451"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5453579425811768,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:36.998808"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "None",
      "llm_response": "There are no respondents with stress scores greater than or equal to 6.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0080926418304443,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:38.012557"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "None",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5589900016784668,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:38.578090"
    },
    {
      "case_id": "case_2",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "None",
      "llm_response": "There is no data provided to answer this question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5326855182647705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:39.118396"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40242528915405273,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:39.524928"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5400264263153076,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:40.069143"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5706017017364502,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:40.646447"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20, 131",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9543247222900391,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.7,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.7,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:41.606401"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "124, 20",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5876107215881348,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:42.202319"
    },
    {
      "case_id": "case_3",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "124, 20",
      "llm_response": "There is no data provided to answer this question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5740582942962646,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:42.782034"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "66, 99",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40535616874694824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:43.194475"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "110,137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5242598056793213,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:43.724842"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "110, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6728205680847168,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:44.402557"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "45, 110, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7192060947418213,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:45.125759"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "110, 137",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6186861991882324,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:45.751358"
    },
    {
      "case_id": "case_4",
      "dataset": "self-reported-mental-health-college-students-2022",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 131, 110, 66, 137",
      "llm_response": "There is no data provided to answer this question.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5684752464294434,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\self-reported-mental-health-college-students-2022\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:46.326469"
    }
  ],
  "stack-overflow-2022-developer-survey/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46604442596435547,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:46.802962"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4792368412017822,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:47.288903"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4322516918182373,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:47.728922"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4115920066833496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:48.144517"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44842982292175293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:48.599650"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the total compensation for respondent 348?",
      "expected_answer": "100000.0",
      "llm_response": "100000.0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.488264799118042,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:49.094169"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4223790168762207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:49.522180"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4152843952178955,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:49.941460"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3993546962738037,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:50.348837"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35750532150268555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:50.710340"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41416049003601074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:51.130897"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 73124?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4294452667236328,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:51.564208"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36698174476623535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:51.937495"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "Employed, full-time",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41121530532836914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:52.353833"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36857032775878906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:52.729065"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3706490993499756,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:53.103713"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36867642402648926,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:53.478112"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the employment status for respondent 444?",
      "expected_answer": "Employed, full-time",
      "llm_response": "A",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37688136100769043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:53.860161"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3948237895965576,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:54.258962"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4466061592102051,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:54.709908"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37740230560302734,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:55.094362"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40523219108581543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:55.506351"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38143372535705566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:55.893010"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the years of coding experience for respondent 73115?",
      "expected_answer": "7",
      "llm_response": "7",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4452352523803711,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:25:56.344190"
    }
  ],
  "stack-overflow-2022-developer-survey/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 3.992750883102417,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:00.343200"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44059014320373535,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:00.789017"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7842998504638672,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:01.581554"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4403359889984131,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:02.029228"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4992043972015381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:02.534440"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72738, 72893",
      "llm_response": "72738, 72893",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44528913497924805,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:02.986132"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45461130142211914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:03.444775"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4546473026275635,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:03.905735"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.588052749633789,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:05.499026"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41666603088378906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:05.920693"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102, 73024",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4324064254760742,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:06.356924"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "102, 73024",
      "llm_response": "102",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3793370723724365,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:06.741420"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5261228084564209,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:07.278328"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.471538782119751,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:07.755080"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5507621765136719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:08.312842"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7312695980072021,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:09.049109"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5173013210296631,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:09.573401"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "382, 29109, 123",
      "llm_response": "382, 29109, 123",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4899942874908447,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:10.068261"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4725663661956787,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:10.545144"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.47954607009887695,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:11.029549"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5404412746429443,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:11.573990"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5153305530548096,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:12.093310"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 409, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5057592391967773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:12.603299"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72740, 73095",
      "llm_response": "72740, 73095",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46936750411987305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:13.076667"
    }
  ],
  "stack-overflow-2022-developer-survey/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4309675693511963,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:13.515657"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4580979347229004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:13.978017"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41582584381103516,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:14.398987"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4643373489379883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:14.867317"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4700350761413574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:15.341347"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 8,
      "llm_response": "8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48596906661987305,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:15.832322"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4741642475128174,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:16.311351"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46428704261779785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:16.780632"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43265700340270996,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:17.217289"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40467262268066406,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:17.625962"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41265010833740234,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:18.042985"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40560007095336914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:18.452756"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42995238304138184,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:18.887719"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40899085998535156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:19.301697"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3821749687194824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:19.688189"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8328292369842529,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:20.524227"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4329519271850586,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:20.962147"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45508289337158203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:21.422032"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45943760871887207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:21.889041"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44767141342163086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:22.341716"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 2.6146113872528076,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:24.960328"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4502532482147217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:25.414587"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42485833168029785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:25.843679"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 4,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4564061164855957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:26.305044"
    }
  ],
  "stack-overflow-2022-developer-survey/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4309539794921875,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:26.744155"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42571473121643066,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:27.175434"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3881056308746338,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:27.567704"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4219479560852051,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:27.993568"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3939957618713379,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:28.394543"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "29115",
      "llm_response": "29115",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4865076541900635,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:28.885802"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39462900161743164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:29.285427"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40210771560668945,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:29.693540"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.823948860168457,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:30.521488"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3850693702697754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:30.912556"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41871047019958496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:31.336278"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "73215",
      "llm_response": "73215",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40353870391845703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:31.744641"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.420121431350708,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:32.170597"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43227195739746094,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:32.608287"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4150722026824951,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:33.027710"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37900733947753906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:33.411035"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "272",
      "llm_response": "There is no respondent with EdLevel E and Country United Kingdom of Great Britain and Northern Ireland in the provided data.",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5393104553222656,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:33.955347"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "272",
      "llm_response": "272",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3852355480194092,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:34.346379"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3999645709991455,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:34.751791"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43970727920532227,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:35.195498"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41446924209594727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:35.617256"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3892362117767334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:36.010500"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5819296836853027,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:36.596379"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72659, 73103",
      "llm_response": "127",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43374085426330566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:37.034766"
    }
  ],
  "stack-overflow-2022-developer-survey/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5987069606781006,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:37.641589"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3983888626098633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:38.044931"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3913295269012451,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:38.441304"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.49671387672424316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:38.942018"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48782992362976074,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:39.435103"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5254523754119873,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:39.965669"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43108153343200684,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:40.401803"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42575979232788086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:40.833564"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40169548988342285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:41.239225"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3987998962402344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:41.644024"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4604318141937256,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:42.109456"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.433668851852417,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:42.547126"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3889651298522949,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:42.941983"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3742380142211914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:43.320187"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7332859039306641,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:44.057473"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42035984992980957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:44.482971"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6640894412994385,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:45.151271"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3846399784088135,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:45.538911"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4382517337799072,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:45.983160"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39137983322143555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:46.378543"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38631677627563477,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:46.770019"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3928794860839844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:47.167787"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4064333438873291,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:47.582229"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 6,
      "llm_response": "6",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43338918685913086,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:48.019573"
    }
  ],
  "stack-overflow-2022-developer-survey/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7983989715576172,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:48.825971"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5651683807373047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:49.395140"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48784399032592773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:49.887993"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7169375419616699,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:50.609928"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4646439552307129,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:51.079456"
    },
    {
      "case_id": "case_1",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "159, 72969, 208",
      "llm_response": "159, 72969, 208",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.660707950592041,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:51.745169"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 73211, 72583, 186, 202, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7196767330169678,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:52.471646"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1400444507598877,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:53.615688"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9570746421813965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:54.578054"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 72887, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.1995699405670166,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:55.782625"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 423, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7258250713348389,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:56.514450"
    },
    {
      "case_id": "case_2",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72710, 186, 359",
      "llm_response": "72710, 72583, 186, 359",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7858614921569824,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:57.305319"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4624507427215576,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:57.771765"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46645402908325195,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:58.242219"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.388770341873169,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:26:59.635563"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5041918754577637,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:00.143841"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4378187656402588,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:00.586626"
    },
    {
      "case_id": "case_3",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72969",
      "llm_response": "72932",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4954664707183838,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:01.085483"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4909627437591553,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:01.581443"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.5802254676818848,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:03.165670"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "29105, 72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6259238719940186,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:03.796594"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7806570529937744,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:04.581479"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48085784912109375,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:05.067322"
    },
    {
      "case_id": "case_4",
      "dataset": "stack-overflow-2022-developer-survey",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "72626",
      "llm_response": "72626",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4342234134674072,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\stack-overflow-2022-developer-survey\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:05.505546"
    }
  ],
  "sus-uta7/answer_lookup": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36862850189208984,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:05.882453"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.382016658782959,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:06.270369"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.524451494216919,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:07.799731"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4634745121002197,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:08.267195"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.452744722366333,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:08.725059"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the group for Clinician 28?",
      "expected_answer": "B",
      "llm_response": "B",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4467194080352783,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:09.178928"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5279080867767334,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:09.710233"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36445021629333496,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:10.078974"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3523523807525635,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:10.436338"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35384058952331543,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:10.796272"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40596723556518555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:11.207316"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 40?",
      "expected_answer": "1",
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8835155963897705,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:12.096924"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4299347400665283,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:12.531027"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5719244480133057,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:13.107823"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3703494071960449,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:13.485167"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7644052505493164,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:14.254548"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35764074325561523,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:14.624143"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the ease of use score for Clinician 10?",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3985145092010498,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:15.026658"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44227147102355957,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:15.473289"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40497875213623047,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:15.883267"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5101611614227295,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:16.397239"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37041163444519043,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:16.772318"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3248589038848877,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:17.102345"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "What is the ease of learning score for Clinician 76?",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4570472240447998,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:17.564595"
    }
  ],
  "sus-uta7/answer_reverse_lookup": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.9975864887237549,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:18.569326"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6635503768920898,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:19.237876"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.685135841369629,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:20.927408"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10,Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4637436866760254,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:21.396460"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41266751289367676,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:21.814846"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 10, Clinician 25",
      "llm_response": "Clinician 10, Clinician 25",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6515870094299316,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:22.471455"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.469041109085083,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:22.944479"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48623156547546387,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:23.434087"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4647035598754883,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:23.902754"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.8456006050109863,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:25.753178"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.8365159034729004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:26.594687"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 8",
      "llm_response": "Clinician 8",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4865901470184326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:27.086667"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43155789375305176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:27.523440"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42112207412719727,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:27.949543"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4109950065612793,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:28.364516"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42175841331481934,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:28.791493"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.35723090171813965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:29.153373"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 38",
      "llm_response": "Clinician 38",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38820481300354004,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:29.546532"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4788477420806885,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:30.029942"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46370840072631836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:30.498651"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40191650390625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:30.905132"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5991036891937256,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:31.509460"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5564594268798828,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:32.070332"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "answer_reverse_lookup",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "Clinician 60, Clinician 74",
      "llm_response": "Clinician 74, Clinician 60",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4475739002227783,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\answer_reverse_lookup\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:32.522886"
    }
  ],
  "sus-uta7/conceptual_aggregation": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46460533142089844,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:32.993659"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4667806625366211,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:33.464392"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.34651923179626465,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:33.815458"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5230567455291748,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:34.343629"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3890397548675537,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:34.737864"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 2,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38664841651916504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:35.129946"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36438727378845215,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:35.498669"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37706875801086426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:35.880085"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3961930274963379,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:36.281091"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0213501453399658,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:37.307293"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6465423107147217,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:37.958768"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7301068305969238,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:38.693716"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4022681713104248,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:39.099990"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43811464309692383,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:39.542765"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7852487564086914,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:40.332014"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4062387943267822,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:40.743200"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.32755255699157715,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:41.076857"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 0,
      "llm_response": "0",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39487576484680176,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:41.476792"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.37752676010131836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:41.858321"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4245316982269287,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:42.286838"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.501680850982666,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:42.792979"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6008110046386719,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:43.398776"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "1",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3836827278137207,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:43.787652"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "conceptual_aggregation",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": 1,
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0587842464447021,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\conceptual_aggregation\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:44.850549"
    }
  ],
  "sus-uta7/multi_hop_relational_inference": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0048789978027344,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:45.861884"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48438167572021484,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:46.350257"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.45101380348205566,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:46.806263"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4093012809753418,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:47.220449"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5214617252349854,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:47.745842"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85",
      "llm_response": "11, 85",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6023092269897461,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:48.352169"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.3297874927520752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:49.685963"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3625054359436035,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:50.052717"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3469808101654053,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:50.404698"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4455115795135498,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:50.855246"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42290520668029785,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:51.283193"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "90, 50",
      "llm_response": "90",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4180443286895752,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:51.704969"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44823312759399414,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:52.157445"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3926401138305664,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:52.555134"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4283323287963867,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:52.988607"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40697240829467773,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:53.399579"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3618204593658447,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:53.765395"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "11, 85, 50, 16, 77, 28",
      "llm_response": "24, 61",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4311530590057373,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:54.202412"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3823864459991455,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:54.589654"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "Answer:",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0022227764129639,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:55.595914"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3314323425292969,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:55.932556"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4131355285644531,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:56.350440"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4377930164337158,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:56.792087"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "multi_hop_relational_inference",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "32, 28",
      "llm_response": "None",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4352447986602783,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.0,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": false,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": false,
        "score": 0.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\multi_hop_relational_inference\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:57.232341"
    }
  ],
  "sus-uta7/respondent_count": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5165383815765381,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:57.755872"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.40053224563598633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:58.162551"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43530869483947754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:58.602859"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4103882312774658,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:59.017253"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7441105842590332,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:27:59.765642"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "4",
      "llm_response": "4",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6051089763641357,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:00.375996"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.4059669971466064,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:01.787226"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39531850814819336,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:02.187562"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4449799060821533,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:02.636826"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.36859583854675293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:03.008649"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3736591339111328,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:03.386537"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "2",
      "llm_response": "2",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6089954376220703,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:04.000746"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3548848628997803,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:04.360809"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4170060157775879,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:04.781816"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.41306495666503906,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:05.199882"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4703359603881836,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:05.680237"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.43218994140625,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:06.115442"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "5",
      "llm_response": "5",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3698914051055908,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:06.489298"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3823211193084717,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:06.876353"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39623546600341797,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:07.280009"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.33722352981567383,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:07.621232"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42413806915283203,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:08.049396"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3769381046295166,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:08.430334"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "respondent_count",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "3",
      "llm_response": "3",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.39142394065856934,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\respondent_count\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:08.827415"
    }
  ],
  "sus-uta7/rule_based_querying": [
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5218973159790039,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\html\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:09.356835"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.529914140701294,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\json\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:09.892007"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4589715003967285,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\md\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:10.354974"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4114563465118408,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:10.771069"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 1.0310635566711426,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:11.807134"
    },
    {
      "case_id": "case_1",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "45, 23",
      "llm_response": "45, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.44173359870910645,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_1.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:12.253520"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.7485306262969971,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\html\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:13.008057"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.5335068702697754,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\json\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:13.545561"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4031345844268799,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\md\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:13.953699"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4258444309234619,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:14.384553"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.38361048698425293,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:14.773133"
    },
    {
      "case_id": "case_2",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "49, 77",
      "llm_response": "49, 77",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.48299074172973633,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_2.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:15.262112"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.845160722732544,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\html\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:16.111245"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.46449995040893555,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\json\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:16.580765"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4304633140563965,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\md\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:17.014211"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4011554718017578,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:17.419590"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.411456823348999,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:17.836931"
    },
    {
      "case_id": "case_3",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "82, 50",
      "llm_response": "82, 50",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.42108798027038574,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_3.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:18.262990"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "html",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "48",
      "llm_response": "55, 48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4270668029785156,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\html\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:18.695190"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "json",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48, 55, 62",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4694702625274658,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\json\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:19.168782"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "md",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48, 55, 40",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.3986787796020508,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\md\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:19.571974"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "ttl",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48, 55, 62",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.4696335792541504,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\ttl\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:20.045911"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "txt",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.6306331157684326,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": true,
      "evaluation_score": 1.0,
      "evaluation_exact_match": true,
      "evaluation_normalized_match": true,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": true,
        "normalized_match": true,
        "partial_match": true,
        "score": 1.0,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\txt\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:20.680544"
    },
    {
      "case_id": "case_4",
      "dataset": "sus-uta7",
      "task": "rule_based_querying",
      "data_format": "xml",
      "config_name": "no_format",
      "question": "",
      "expected_answer": "48",
      "llm_response": "48, 40, 23",
      "llm_success": true,
      "llm_error": null,
      "response_time": 0.74051833152771,
      "model": "gemini-1.5-flash",
      "provider": "google",
      "evaluation_correct": false,
      "evaluation_score": 0.9,
      "evaluation_exact_match": false,
      "evaluation_normalized_match": false,
      "evaluation_partial_match": true,
      "evaluation_details": {
        "exact_match": false,
        "normalized_match": false,
        "partial_match": true,
        "score": 0.9,
        "error": null
      },
      "prompt_file": "benchmark_results\\benchmark_google\\config_no_format_20250723_092207\\prompts\\sus-uta7\\rule_based_querying\\xml\\case_4.txt",
      "config": {
        "include_one_shot": true,
        "include_partition": true,
        "include_role": true,
        "include_format": false,
        "data_at_end": false
      },
      "timestamp": "2025-07-23T09:28:21.425047"
    }
  ]
}